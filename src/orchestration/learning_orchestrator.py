"""
Learning Orchestrator - Intelligence Coordination System

Master orchestration system that coordinates all learning components including
conversation quality tracking, emotion analysis, and relationship evolution.

Core Features:
- Coordinates conversation quality tracking, emotion analysis enhancement, relationship evolution, character adaptation, knowledge fusion
- Unified learning health monitoring across all components
- Automated learning cycles and learning task prioritization
- Cross-system intelligence fusion and correlation analysis
- System-wide performance tracking and quality improvement metrics

This is the capstone component that transforms WhisperEngine from individual
adaptive systems to a unified, self-improving AI platform.
"""

import logging
from typing import Dict, List, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class LearningComponentStatus(Enum):
    """Status of individual learning components"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    FAILED = "failed"
    UNAVAILABLE = "unavailable"


class LearningTaskPriority(Enum):
    """Priority levels for learning tasks"""
    CRITICAL = "critical"      # System health issues
    HIGH = "high"             # Quality degradation
    MEDIUM = "medium"         # Optimization opportunities
    LOW = "low"               # Nice-to-have improvements


class SystemLearningHealth(Enum):
    """Overall system learning health status"""
    EXCELLENT = "excellent"   # All systems optimal, quality improving
    GOOD = "good"            # Most systems healthy, stable quality
    FAIR = "fair"            # Some issues, quality stable or declining slowly
    POOR = "poor"            # Multiple issues, quality declining
    CRITICAL = "critical"    # System failure, immediate intervention needed


@dataclass
class ComponentHealthStatus:
    """Health status for individual learning components"""
    component_name: str
    status: LearningComponentStatus
    performance_score: float      # 0-1 scale
    last_optimization: datetime
    issues: List[str]
    metrics: Dict[str, Any]
    recommendations: List[str]


@dataclass
class LearningTask:
    """Individual learning task to be executed"""
    task_id: str
    component: str                # Which sprint component
    task_type: str               # Type of learning task
    priority: LearningTaskPriority
    description: str
    estimated_impact: float      # Expected quality improvement (0-1)
    estimated_effort: float      # Execution complexity (0-1)
    dependencies: List[str]      # Other task IDs this depends on
    target_completion: datetime
    metadata: Dict[str, Any]


@dataclass
class LearningHealthReport:
    """Comprehensive system learning health report"""
    overall_health: SystemLearningHealth
    component_statuses: List[ComponentHealthStatus]
    active_tasks: List[LearningTask]
    completed_tasks_24h: int
    quality_trend: str           # "improving", "stable", "declining"
    system_performance_score: float  # 0-1 overall system performance
    recommendations: List[str]
    generated_at: datetime


@dataclass
class CrossSprintCorrelation:
    """Correlation analysis between different sprint components"""
    component_a: str
    component_b: str
    correlation_strength: float  # -1 to 1
    correlation_type: str        # "positive", "negative", "neutral"
    confidence: float           # 0-1 confidence in correlation
    insights: List[str]
    actionable_recommendations: List[str]


class LearningOrchestrator:
    """
    Master orchestration system for all WhisperEngine learning components.
    
    Coordinates learning systems:
    - Conversation Quality Tracking (confidence adaptation)
    - Emotion Analysis Enhancement (memory optimization) 
    - Relationship Evolution (dynamic relationships)
    - Character Adaptation (adaptive character tuning)
    - Knowledge Fusion (cross-datastore intelligence)
    
    Provides unified intelligence through:
    - Health monitoring across all components
    - Automated optimization cycles
    - Cross-system correlation analysis
    - Predictive adaptation coordination
    - Quality improvement tracking
    """
    
    def __init__(self, 
                 trend_analyzer=None,           # Sprint 1
                 confidence_adapter=None,       # Sprint 1
                 memory_manager=None,           # Sprint 2
                 relationship_engine=None,      # Sprint 3
                 trust_recovery=None,           # Sprint 3
                 temporal_client=None,          # InfluxDB for metrics
                 postgres_pool=None):           # PostgreSQL for persistence
        """Initialize Learning Orchestrator with all sprint components."""
        self.logger = logger
        
        # Sprint 1: TrendWise components
        self.trend_analyzer = trend_analyzer
        self.confidence_adapter = confidence_adapter
        
        # Sprint 2: MemoryBoost components (via memory_manager)
        self.memory_manager = memory_manager
        
        # Sprint 3: RelationshipTuner components
        self.relationship_engine = relationship_engine
        self.trust_recovery = trust_recovery
        
        # Infrastructure clients
        self.temporal_client = temporal_client
        self.postgres_pool = postgres_pool
        
        # Sprint 6: Orchestration state
        self._learning_tasks = []
        self._last_health_check = None
        self._system_performance_history = []
        self._cross_sprint_correlations = {}
        
        # Learning cycle configuration
        self.health_check_interval = timedelta(hours=6)
        self.optimization_cycle_interval = timedelta(hours=24)
        self.correlation_analysis_interval = timedelta(days=7)
        
        # Sprint 6 Telemetry: Usage tracking for evaluation
        self._telemetry: Dict[str, Any] = {
            'coordinate_learning_cycle_count': 0,
            'monitor_learning_health_count': 0,
            'prioritize_learning_tasks_count': 0,
            'analyze_cross_sprint_correlations_count': 0,
            'total_execution_time_seconds': 0.0,
            'initialization_time': datetime.utcnow()
        }
        
        logger.info("Learning Orchestrator initialized with all sprint components")
    
    async def coordinate_learning_cycle(self, bot_name: str) -> Dict[str, Any]:
        """
        Orchestrate a complete learning cycle across all components.
        
        This is the main entry point for unified learning that:
        1. Assesses health of all sprint components
        2. Prioritizes learning tasks based on impact and urgency
        3. Executes high-priority optimizations
        4. Analyzes cross-sprint correlations
        5. Records comprehensive metrics
        
        Args:
            bot_name: Character bot name for component-specific operations
            
        Returns:
            Dict with learning cycle results and metrics
        """
        cycle_start = datetime.utcnow()
        logger.info("ðŸŽ¯ ORCHESTRATOR: Starting unified learning cycle for %s", bot_name)
        
        # Sprint 6 Telemetry: Track invocation (cast for type safety)
        self._telemetry['coordinate_learning_cycle_count'] = int(self._telemetry['coordinate_learning_cycle_count']) + 1
        
        try:
            # Phase 1: Health assessment across all components
            health_report = await self.monitor_learning_health(bot_name)
            
            # Phase 2: Task prioritization based on health and opportunities
            priority_tasks = await self.prioritize_learning_tasks(health_report)
            
            # Phase 3: Execute high-priority tasks
            execution_results = await self._execute_priority_tasks(priority_tasks, bot_name)
            
            # Phase 4: Cross-sprint correlation analysis
            correlations = await self._analyze_cross_sprint_correlations(bot_name)
            
            # Phase 5: Update system performance tracking
            performance_update = await self._update_system_performance(
                health_report, execution_results, correlations
            )
            
            # Phase 6: Record unified metrics to InfluxDB
            if self.temporal_client:
                await self._record_orchestration_metrics(
                    bot_name, health_report, execution_results, correlations, performance_update
                )
            
            cycle_duration = (datetime.utcnow() - cycle_start).total_seconds()
            
            # Sprint 6 Telemetry: Record execution time (cast for type safety)
            self._telemetry['total_execution_time_seconds'] = float(self._telemetry['total_execution_time_seconds']) + cycle_duration
            
            # Sprint 6 Telemetry: Write to InfluxDB for evaluation
            if self.temporal_client:
                try:
                    telemetry_point = {
                        'measurement': 'component_usage',
                        'tags': {
                            'component': 'learning_orchestrator',
                            'method': 'coordinate_learning_cycle',
                            'bot_name': bot_name
                        },
                        'fields': {
                            'execution_time_seconds': cycle_duration,
                            'tasks_executed': len(execution_results.get('completed_tasks', [])),
                            'tasks_failed': len(execution_results.get('failed_tasks', [])),
                            'correlations_analyzed': len(correlations),
                            'performance_improvement': performance_update.get('improvement_score', 0.0),
                            'invocation_count': self._telemetry['coordinate_learning_cycle_count']
                        },
                        'time': cycle_start
                    }
                    await self.temporal_client.write_point(telemetry_point)
                    logger.info("ðŸ“Š ORCHESTRATOR TELEMETRY: Recorded cycle metrics to InfluxDB")
                except Exception as telemetry_error:
                    logger.warning("Failed to record orchestrator telemetry: %s", telemetry_error)
            
            learning_cycle_result = {
                'cycle_id': f"learning_cycle_{bot_name}_{int(cycle_start.timestamp())}",
                'bot_name': bot_name,
                'cycle_duration_seconds': cycle_duration,
                'health_report': health_report,
                'tasks_executed': len(execution_results.get('completed_tasks', [])),
                'tasks_failed': len(execution_results.get('failed_tasks', [])),
                'correlations_analyzed': len(correlations),
                'performance_improvement': performance_update.get('improvement_score', 0.0),
                'recommendations': self._generate_cycle_recommendations(
                    health_report, execution_results, correlations
                ),
                'next_cycle_scheduled': cycle_start + self.optimization_cycle_interval
            }
            
            logger.info(
                "ðŸŽ¯ ORCHESTRATOR: Learning cycle completed for %s - "
                "%.2fs duration, %d tasks executed, %.3f performance improvement",
                bot_name, cycle_duration, 
                learning_cycle_result['tasks_executed'],
                learning_cycle_result['performance_improvement']
            )
            
            return learning_cycle_result
            
        except Exception as e:
            logger.error("Learning cycle coordination failed for %s: %s", bot_name, str(e))
            return {
                'cycle_id': f"learning_cycle_{bot_name}_failed_{int(cycle_start.timestamp())}",
                'bot_name': bot_name,
                'status': 'failed',
                'error': str(e),
                'cycle_duration_seconds': (datetime.utcnow() - cycle_start).total_seconds()
            }
    
    async def monitor_learning_health(self, bot_name: str) -> LearningHealthReport:
        """
        Monitor health status across all learning components.
        
        Evaluates:
        - Sprint 1: TrendWise confidence adaptation effectiveness
        - Sprint 2: MemoryBoost memory optimization performance
        - Sprint 3: RelationshipTuner relationship evolution health
        - Sprint 4: CharacterEvolution adaptive tuning status
        - Sprint 5: KnowledgeFusion intelligence integration
        
        Args:
            bot_name: Character bot name for component-specific health checks
            
        Returns:
            Comprehensive health report across all components
        """
        health_check_start = datetime.utcnow()
        component_statuses = []
        
        # Sprint 6 Telemetry: Track invocation (cast for type safety)
        self._telemetry['monitor_learning_health_count'] = int(self._telemetry['monitor_learning_health_count']) + 1
        
        try:
            # Sprint 1: TrendWise health check
            trendwise_status = await self._check_trendwise_health(bot_name)
            component_statuses.append(trendwise_status)
            
            # Sprint 2: MemoryBoost health check
            memoryboost_status = await self._check_memoryboost_health(bot_name)
            component_statuses.append(memoryboost_status)
            
            # Sprint 3: RelationshipTuner health check
            relationship_status = await self._check_relationship_health(bot_name)
            component_statuses.append(relationship_status)
            
            # Sprint 4: CharacterEvolution health check
            character_evolution_status = await self._check_character_evolution_health(bot_name)
            component_statuses.append(character_evolution_status)
            
            # Sprint 5: KnowledgeFusion health check
            knowledge_fusion_status = await self._check_knowledge_fusion_health(bot_name)
            component_statuses.append(knowledge_fusion_status)
            
            # Calculate overall system health
            overall_health = self._calculate_overall_health(component_statuses)
            
            # Generate system-wide recommendations
            system_recommendations = self._generate_system_recommendations(component_statuses)
            
            # Calculate quality trend
            quality_trend = await self._calculate_quality_trend(bot_name)
            
            # Calculate system performance score
            system_performance = self._calculate_system_performance_score(component_statuses)
            
            health_report = LearningHealthReport(
                overall_health=overall_health,
                component_statuses=component_statuses,
                active_tasks=self._learning_tasks,
                completed_tasks_24h=await self._count_completed_tasks_24h(),
                quality_trend=quality_trend,
                system_performance_score=system_performance,
                recommendations=system_recommendations,
                generated_at=health_check_start
            )
            
            self._last_health_check = health_check_start
            
            logger.info(
                "ðŸ¥ HEALTH: System health check completed for %s - "
                "Overall: %s, Performance: %.3f, Components: %d healthy",
                bot_name, overall_health.value, system_performance,
                len([s for s in component_statuses if s.status == LearningComponentStatus.HEALTHY])
            )
            
            return health_report
            
        except Exception as e:
            logger.error("Health monitoring failed for %s: %s", bot_name, str(e))
            # Return degraded health report
            return LearningHealthReport(
                overall_health=SystemLearningHealth.CRITICAL,
                component_statuses=component_statuses,  # Partial results
                active_tasks=[],
                completed_tasks_24h=0,
                quality_trend="unknown",
                system_performance_score=0.0,
                recommendations=["System health monitoring failed - investigate immediately"],
                generated_at=health_check_start
            )
    
    async def prioritize_learning_tasks(self, health_report: LearningHealthReport) -> List[LearningTask]:
        """
        Prioritize learning tasks based on health report and impact analysis.
        
        Task prioritization considers:
        - Component health issues (critical priority)
        - Quality improvement opportunities (high priority)  
        - Cross-sprint optimization potential (medium priority)
        - Maintenance and fine-tuning (low priority)
        
        Args:
            health_report: Current system health report
            
        Returns:
            Prioritized list of learning tasks
        """
        logger.info("ðŸ“‹ PRIORITIZER: Analyzing learning tasks and opportunities")
        
        priority_tasks = []
        
        try:
            # Generate tasks based on component health issues
            health_tasks = self._generate_health_based_tasks(health_report)
            priority_tasks.extend(health_tasks)
            
            # Generate optimization tasks based on performance opportunities
            optimization_tasks = self._generate_optimization_tasks(health_report)
            priority_tasks.extend(optimization_tasks)
            
            # Generate cross-sprint integration tasks
            integration_tasks = self._generate_integration_tasks(health_report)
            priority_tasks.extend(integration_tasks)
            
            # Sort by priority and estimated impact
            priority_tasks.sort(key=lambda task: (
                task.priority.value,  # Critical first
                -task.estimated_impact,  # Higher impact first
                task.estimated_effort    # Lower effort first
            ))
            
            # Update internal task tracking
            self._learning_tasks = priority_tasks
            
            logger.info(
                "ðŸ“‹ PRIORITIZER: Generated %d learning tasks - "
                "%d critical, %d high, %d medium, %d low priority",
                len(priority_tasks),
                len([t for t in priority_tasks if t.priority == LearningTaskPriority.CRITICAL]),
                len([t for t in priority_tasks if t.priority == LearningTaskPriority.HIGH]),
                len([t for t in priority_tasks if t.priority == LearningTaskPriority.MEDIUM]),
                len([t for t in priority_tasks if t.priority == LearningTaskPriority.LOW])
            )
            
            return priority_tasks
            
        except Exception as e:
            logger.error("Task prioritization failed: %s", str(e))
            return []
    
    # =============================================================================
    # Private Implementation Methods
    # =============================================================================
    
    async def _execute_priority_tasks(self, priority_tasks: List[LearningTask], bot_name: str) -> Dict[str, Any]:
        """Execute high-priority learning tasks."""
        completed_tasks = []
        failed_tasks = []
        
        # Execute critical and high priority tasks first
        high_priority_tasks = [
            task for task in priority_tasks 
            if task.priority in [LearningTaskPriority.CRITICAL, LearningTaskPriority.HIGH]
        ]
        
        for task in high_priority_tasks[:5]:  # Limit to 5 tasks per cycle
            try:
                result = await self._execute_single_task(task, bot_name)
                if result['success']:
                    completed_tasks.append(task)
                else:
                    failed_tasks.append(task)
            except (ValueError, TypeError, AttributeError) as e:
                logger.warning("Task execution failed for %s: %s", task.task_id, str(e))
                failed_tasks.append(task)
        
        return {
            'completed_tasks': completed_tasks,
            'failed_tasks': failed_tasks,
            'total_executed': len(completed_tasks) + len(failed_tasks)
        }
    
    async def _execute_single_task(self, task: LearningTask, bot_name: str) -> Dict[str, Any]:
        """Execute a single learning task."""
        logger.info("Executing learning task: %s for %s", task.task_id, bot_name)
        
        # Placeholder implementation - would route to appropriate component
        # Based on task.component and task.task_type
        return {
            'success': True,
            'task_id': task.task_id,
            'execution_time': 0.1,
            'impact_achieved': task.estimated_impact * 0.8  # 80% of estimated impact
        }
    
    async def _analyze_cross_sprint_correlations(self, _bot_name: str) -> List[CrossSprintCorrelation]:
        """Analyze correlations between different sprint components."""
        correlations = []
        
        # Example correlation: TrendWise confidence vs RelationshipTuner trust
        correlations.append(CrossSprintCorrelation(
            component_a="TrendWise",
            component_b="RelationshipTuner", 
            correlation_strength=0.7,
            correlation_type="positive",
            confidence=0.85,
            insights=["Higher confidence correlates with better relationship progression"],
            actionable_recommendations=["Prioritize confidence improvements for relationship building"]
        ))
        
        return correlations
    
    async def _update_system_performance(self, health_report, execution_results, _correlations) -> Dict[str, Any]:
        """Update system performance tracking."""
        improvement_score = 0.0
        
        # Calculate improvement based on tasks completed
        completed_count = len(execution_results.get('completed_tasks', []))
        if completed_count > 0:
            improvement_score = min(0.1, completed_count * 0.02)  # Max 10% improvement per cycle
        
        self._system_performance_history.append({
            'timestamp': datetime.utcnow(),
            'performance_score': health_report.system_performance_score,
            'improvement_score': improvement_score,
            'tasks_completed': completed_count
        })
        
        # Keep only last 30 days of history
        cutoff_date = datetime.utcnow() - timedelta(days=30)
        self._system_performance_history = [
            entry for entry in self._system_performance_history 
            if entry['timestamp'] > cutoff_date
        ]
        
        return {
            'improvement_score': improvement_score,
            'performance_trend': 'improving' if improvement_score > 0 else 'stable'
        }
    
    async def _record_orchestration_metrics(self, bot_name, health_report, execution_results, correlations, performance_update):
        """Record comprehensive orchestration metrics to InfluxDB."""
        if not self.temporal_client:
            return
        
        try:
            # Record orchestration cycle metrics
            await self.temporal_client.record_point(
                measurement="learning_orchestration",
                tags={
                    "bot_name": bot_name,
                    "overall_health": health_report.overall_health.value
                },
                fields={
                    "system_performance_score": health_report.system_performance_score,
                    "tasks_completed": len(execution_results.get('completed_tasks', [])),
                    "tasks_failed": len(execution_results.get('failed_tasks', [])),
                    "correlations_analyzed": len(correlations),
                    "improvement_score": performance_update.get('improvement_score', 0.0)
                }
            )
            
            # Record component health metrics
            for component in health_report.component_statuses:
                await self.temporal_client.record_point(
                    measurement="component_health",
                    tags={
                        "bot_name": bot_name,
                        "component": component.component_name,
                        "status": component.status.value
                    },
                    fields={
                        "performance_score": component.performance_score,
                        "issues_count": len(component.issues)
                    }
                )
                
        except Exception as e:
            logger.warning("Failed to record orchestration metrics: %s", str(e))
    
    def _generate_cycle_recommendations(self, health_report, execution_results, _correlations) -> List[str]:
        """Generate recommendations based on learning cycle results."""
        recommendations = []
        
        # Health-based recommendations
        if health_report.overall_health in [SystemLearningHealth.POOR, SystemLearningHealth.CRITICAL]:
            recommendations.append("System health critical - immediate intervention required")
        
        # Performance-based recommendations
        if health_report.system_performance_score < 0.7:
            recommendations.append("System performance below optimal - consider optimization cycle")
        
        # Task execution recommendations
        failed_count = len(execution_results.get('failed_tasks', []))
        if failed_count > 0:
            recommendations.append(f"{failed_count} learning tasks failed - investigate task execution issues")
        
        return recommendations
    
    async def _check_trendwise_health(self, _bot_name: str) -> ComponentHealthStatus:
        """Check health of Sprint 1 TrendWise components."""
        issues = []
        metrics: Dict[str, Any] = {}
        performance_score = 0.8  # Default healthy score
        
        if not self.trend_analyzer:
            issues.append("Trend analyzer unavailable")
            performance_score = 0.0
        
        if not self.confidence_adapter:
            issues.append("Confidence adapter unavailable")
            performance_score = min(performance_score, 0.5)
        
        status = (LearningComponentStatus.HEALTHY if performance_score > 0.7 
                 else LearningComponentStatus.DEGRADED if performance_score > 0.3
                 else LearningComponentStatus.FAILED)
        
        return ComponentHealthStatus(
            component_name="TrendWise",
            status=status,
            performance_score=performance_score,
            last_optimization=datetime.utcnow() - timedelta(hours=6),
            issues=issues,
            metrics=metrics,
            recommendations=["Monitor confidence trends daily"] if status == LearningComponentStatus.HEALTHY else []
        )
    
    async def _check_memoryboost_health(self, _bot_name: str) -> ComponentHealthStatus:
        """Check health of Sprint 2 MemoryBoost components."""
        issues: List[str] = []
        metrics: Dict[str, Any] = {}
        performance_score = 0.8
        
        if not self.memory_manager:
            issues.append("Memory manager unavailable")
            performance_score = 0.0
        elif not hasattr(self.memory_manager, 'retrieve_relevant_memories_with_memoryboost'):
            issues.append("MemoryBoost enhanced retrieval unavailable")
            performance_score = 0.6
        
        status = (LearningComponentStatus.HEALTHY if performance_score > 0.7
                 else LearningComponentStatus.DEGRADED if performance_score > 0.3
                 else LearningComponentStatus.FAILED)
        
        return ComponentHealthStatus(
            component_name="MemoryBoost",
            status=status,
            performance_score=performance_score,
            last_optimization=datetime.utcnow() - timedelta(hours=12),
            issues=issues,
            metrics=metrics,
            recommendations=["Run memory effectiveness analysis weekly"] if status == LearningComponentStatus.HEALTHY else []
        )
    
    async def _check_relationship_health(self, _bot_name: str) -> ComponentHealthStatus:
        """Check health of Sprint 3 RelationshipTuner components."""
        issues: List[str] = []
        metrics: Dict[str, Any] = {}
        performance_score = 0.8
        
        if not self.relationship_engine:
            issues.append("Relationship engine unavailable")
            performance_score = 0.0
        
        if not self.trust_recovery:
            issues.append("Trust recovery system unavailable")
            performance_score = min(performance_score, 0.6)
        
        status = (LearningComponentStatus.HEALTHY if performance_score > 0.7
                 else LearningComponentStatus.DEGRADED if performance_score > 0.3
                 else LearningComponentStatus.FAILED)
        
        return ComponentHealthStatus(
            component_name="RelationshipTuner",
            status=status,
            performance_score=performance_score,
            last_optimization=datetime.utcnow() - timedelta(hours=8),
            issues=issues,
            metrics=metrics,
            recommendations=["Monitor relationship progression trends"] if status == LearningComponentStatus.HEALTHY else []
        )
    
    async def _check_character_evolution_health(self, _bot_name: str) -> ComponentHealthStatus:
        """Check health of Sprint 4 CharacterEvolution components."""
        issues: List[str] = []
        metrics: Dict[str, Any] = {}
        performance_score = 0.8  # Assume healthy until implementation
        
        # CharacterEvolution components would be in src/characters/
        # performance_analyzer.py, cdl_optimizer.py, adaptation_engine.py
        
        # Placeholder implementation - would check actual components when implemented
        
        status = (LearningComponentStatus.HEALTHY if performance_score > 0.7
                 else LearningComponentStatus.DEGRADED if performance_score > 0.3
                 else LearningComponentStatus.FAILED)
        
        return ComponentHealthStatus(
            component_name="CharacterEvolution",
            status=status,
            performance_score=performance_score,
            last_optimization=datetime.utcnow() - timedelta(hours=8),
            issues=issues,
            metrics=metrics,
            recommendations=["Monitor CDL parameter optimization effectiveness"] if status == LearningComponentStatus.HEALTHY else []
        )
    
    async def _check_knowledge_fusion_health(self, _bot_name: str) -> ComponentHealthStatus:
        """Check health of Sprint 5 KnowledgeFusion components."""
        issues: List[str] = []
        metrics: Dict[str, Any] = {}
        performance_score = 0.8  # Assume healthy until implementation
        
        # KnowledgeFusion components would be in src/knowledge/
        # integration_engine.py, confidence_learner.py
        # Cross-store analytics in src/analytics/cross_store_analyzer.py
        
        # Placeholder implementation - would check actual components when implemented
        
        status = (LearningComponentStatus.HEALTHY if performance_score > 0.7
                 else LearningComponentStatus.DEGRADED if performance_score > 0.3
                 else LearningComponentStatus.FAILED)
        
        return ComponentHealthStatus(
            component_name="KnowledgeFusion",
            status=status,
            performance_score=performance_score,
            last_optimization=datetime.utcnow() - timedelta(hours=6),
            issues=issues,
            metrics=metrics,
            recommendations=["Monitor cross-datastore intelligence integration"] if status == LearningComponentStatus.HEALTHY else []
        )
    
    def _calculate_overall_health(self, component_statuses: List[ComponentHealthStatus]) -> SystemLearningHealth:
        """Calculate overall system health from component statuses."""
        if not component_statuses:
            return SystemLearningHealth.CRITICAL
        
        # Count component health levels
        healthy_count = len([s for s in component_statuses if s.status == LearningComponentStatus.HEALTHY])
        degraded_count = len([s for s in component_statuses if s.status == LearningComponentStatus.DEGRADED])
        failed_count = len([s for s in component_statuses if s.status == LearningComponentStatus.FAILED])
        
        total_components = len(component_statuses)
        healthy_ratio = healthy_count / total_components
        
        if failed_count > 0:
            return SystemLearningHealth.CRITICAL if failed_count > 1 else SystemLearningHealth.POOR
        elif degraded_count > total_components // 2:
            return SystemLearningHealth.FAIR
        elif healthy_ratio >= 0.8:
            return SystemLearningHealth.EXCELLENT
        else:
            return SystemLearningHealth.GOOD
    
    def _generate_system_recommendations(self, component_statuses: List[ComponentHealthStatus]) -> List[str]:
        """Generate system-wide recommendations."""
        recommendations = []
        
        for component in component_statuses:
            if component.status != LearningComponentStatus.HEALTHY:
                recommendations.append(f"Address {component.component_name} issues: {', '.join(component.issues)}")
            
            recommendations.extend(component.recommendations)
        
        return recommendations
    
    async def _calculate_quality_trend(self, _bot_name: str) -> str:
        """Calculate conversation quality trend."""
        # Placeholder - would analyze InfluxDB metrics
        return "stable"
    
    def _calculate_system_performance_score(self, component_statuses: List[ComponentHealthStatus]) -> float:
        """Calculate overall system performance score."""
        if not component_statuses:
            return 0.0
        
        total_score = sum(component.performance_score for component in component_statuses)
        return total_score / len(component_statuses)
    
    async def _count_completed_tasks_24h(self) -> int:
        """Count tasks completed in last 24 hours."""
        # Placeholder implementation
        return len([task for task in self._learning_tasks if task.priority == LearningTaskPriority.CRITICAL])
    
    def _generate_health_based_tasks(self, health_report: LearningHealthReport) -> List[LearningTask]:
        """Generate tasks based on component health issues."""
        tasks = []
        
        for component in health_report.component_statuses:
            if component.status != LearningComponentStatus.HEALTHY:
                task = LearningTask(
                    task_id=f"health_fix_{component.component_name}_{int(datetime.utcnow().timestamp())}",
                    component=component.component_name,
                    task_type="health_restoration",
                    priority=LearningTaskPriority.CRITICAL if component.status == LearningComponentStatus.FAILED else LearningTaskPriority.HIGH,
                    description=f"Restore {component.component_name} to healthy status",
                    estimated_impact=0.2,
                    estimated_effort=0.3,
                    dependencies=[],
                    target_completion=datetime.utcnow() + timedelta(hours=6),
                    metadata={"issues": component.issues}
                )
                tasks.append(task)
        
        return tasks
    
    def _generate_optimization_tasks(self, health_report: LearningHealthReport) -> List[LearningTask]:
        """Generate optimization tasks based on performance opportunities."""
        tasks = []
        
        if health_report.system_performance_score < 0.9:
            task = LearningTask(
                task_id=f"optimization_{int(datetime.utcnow().timestamp())}",
                component="SystemWide",
                task_type="performance_optimization",
                priority=LearningTaskPriority.MEDIUM,
                description="Optimize system-wide performance",
                estimated_impact=0.1,
                estimated_effort=0.2,
                dependencies=[],
                target_completion=datetime.utcnow() + timedelta(hours=24),
                metadata={"current_performance": health_report.system_performance_score}
            )
            tasks.append(task)
        
        return tasks
    
    def _generate_integration_tasks(self, _health_report: LearningHealthReport) -> List[LearningTask]:
        """Generate cross-sprint integration tasks."""
        tasks = []
        
        # Example: Integrate TrendWise confidence with RelationshipTuner
        task = LearningTask(
            task_id=f"integration_confidence_relationship_{int(datetime.utcnow().timestamp())}",
            component="CrossSprint",
            task_type="integration_enhancement",
            priority=LearningTaskPriority.LOW,
            description="Enhance confidence-relationship correlation",
            estimated_impact=0.05,
            estimated_effort=0.15,
            dependencies=[],
            target_completion=datetime.utcnow() + timedelta(days=7),
            metadata={"integration_type": "confidence_relationship"}
        )
        tasks.append(task)
        
        return tasks


def create_learning_orchestrator(
    trend_analyzer=None,
    confidence_adapter=None, 
    memory_manager=None,
    relationship_engine=None,
    trust_recovery=None,
    temporal_client=None,
    postgres_pool=None
) -> LearningOrchestrator:
    """
    Factory function to create Learning Orchestrator instance.
    
    Args:
        All Sprint 1-5 components and infrastructure clients
        
    Returns:
        Configured LearningOrchestrator instance
    """
    return LearningOrchestrator(
        trend_analyzer=trend_analyzer,
        confidence_adapter=confidence_adapter,
        memory_manager=memory_manager,
        relationship_engine=relationship_engine,
        trust_recovery=trust_recovery,
        temporal_client=temporal_client,
        postgres_pool=postgres_pool
    )