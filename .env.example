# =======================================================
# WhisperEngine Configuration Template
# Copy this to .env and configure for your setup
# =======================================================

# =======================================================
# DEPLOYMENT MODE (auto-detected if not set)
# =======================================================
# ENV_MODE=development
# Options: development, desktop, discord, production

# =======================================================
# REQUIRED DISCORD CONFIGURATION
# =======================================================
# Discord Bot Token (required for Discord bot mode)
# Get from: https://discord.com/developers/applications
DISCORD_BOT_TOKEN=your_discord_bot_token_here

# Bot Configuration
DISCORD_BOT_NAME=whisperengine
ADMIN_USER_IDS=your_discord_user_id_here

# Discord Bot Settings (defaults shown)
DISCORD_COMMAND_PREFIX=!
DISCORD_HEARTBEAT_TIMEOUT=60.0
DISCORD_HEARTBEAT_CHECK_INTERVAL=10.0
DISCORD_CHUNK_GUILDS=false
DISCORD_LLM_TIMEOUT=120

# Demo Bot Flag (shows data handling warnings)
DEMO_BOT=false

# =======================================================
# LLM CONFIGURATION
# =======================================================

# === CHAT LLM (Primary Conversation) ===
LLM_CHAT_API_URL=http://localhost:1234/v1
LLM_CHAT_API_KEY=
LLM_CHAT_MODEL=local-model
LLM_MAX_TOKENS_CHAT=4096

# === FACTS LLM (Fact Extraction) ===
LLM_FACTS_API_URL=
LLM_FACTS_API_KEY=
LLM_FACTS_MODEL=
LLM_MAX_TOKENS_FACT_EXTRACTION=500

# === EMOTION LLM (Emotional Analysis) ===
LLM_EMOTION_API_URL=
LLM_EMOTION_API_KEY=
LLM_EMOTION_MODEL=
LLM_MAX_TOKENS_EMOTION=200

# === LLM Performance Settings ===
LLM_MAX_TOKENS_COMPLETION=1024
LLM_MAX_TOKENS_PERSONAL_INFO=400
LLM_MAX_TOKENS_TRUST_DETECTION=300
LLM_MAX_TOKENS_USER_FACTS=400
LLM_REQUEST_TIMEOUT=90
LLM_CONNECTION_TIMEOUT=10

# === Vision Support ===
LLM_SUPPORTS_VISION=false
LLM_VISION_MAX_IMAGES=5

# === Local Model Configuration ===
LOCAL_LLM_MODEL=microsoft_Phi-3-mini-4k-instruct

# =======================================================
# DATABASE CONFIGURATION
# =======================================================

# === SQLite (Default - Local Storage) ===
USE_SQLITE=true

# === PostgreSQL (Production) ===
USE_POSTGRESQL=false
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=whisper_engine
POSTGRES_USER=bot_user
POSTGRES_PASSWORD=bot_password_change_me
POSTGRES_MIN_CONNECTIONS=5
POSTGRES_MAX_CONNECTIONS=20

# === Redis (Caching) ===
USE_REDIS_CACHE=false
REDIS_HOST=localhost

# === ChromaDB (Vector Database) ===
CHROMADB_HOST=localhost
CHROMADB_PORT=8000
CHROMADB_PATH=./chromadb_data
CHROMADB_COLLECTION_NAME=user_memories
CHROMADB_GLOBAL_COLLECTION_NAME=global_facts
USE_CHROMADB_HTTP=false
ANONYMIZED_TELEMETRY=false

# === Neo4j Graph Database (Optional) ===
ENABLE_GRAPH_DATABASE=false

# =======================================================
# MEMORY & AI INTELLIGENCE CONFIGURATION
# =======================================================

# === Memory Optimization ===
ENABLE_MEMORY_OPTIMIZATION=auto
MEMORY_OPTIMIZATION_LEVEL=auto
MEMORY_CACHE_SIZE=auto
ENABLE_MEMORY_MONITORING=auto

# === AI Intelligence Phases ===
ENABLE_EMOTIONAL_INTELLIGENCE=true
ENABLE_PHASE3_MEMORY=true
AI_MEMORY_OPTIMIZATION=true
AI_EMOTIONAL_RESONANCE=true
AI_ADAPTIVE_MODE=true
AI_PERSONALITY_ANALYSIS=true
ENABLE_DYNAMIC_PERSONALITY=true

# === Adaptive Prompt Engineering ===
ADAPTIVE_PROMPT_ENABLED=true                    # Enable/disable adaptive prompt system
ADAPTIVE_PROMPT_FORCE_SIZE=                     # Override auto-detection (small/medium/large)
ADAPTIVE_PROMPT_TOKEN_BUDGET=                   # Override default token budget
ADAPTIVE_PROMPT_COMPRESSION_LEVEL=balanced      # aggressive/balanced/minimal
ADAPTIVE_PROMPT_PERFORMANCE_MODE=quality        # fast/balanced/quality
ADAPTIVE_PROMPT_DEBUG=false                     # Enable detailed logging

# === Model-Specific Overrides ===
SMALL_MODEL_MAX_PROMPT=500                      # Max prompt size for small models (1B-3B params)
MEDIUM_MODEL_MAX_PROMPT=1000                    # Max prompt size for medium models (3B-8B params)
LARGE_MODEL_MAX_PROMPT=2000                     # Max prompt size for large models (8B+ params)

# === Template Selection ===
ADAPTIVE_TEMPLATE_PREFERENCE=optimized          # default/optimized/minimal
ADAPTIVE_CONTEXT_STRATEGY=smart_truncation      # truncate/compress/prioritize

# === Phase 4 Human-Like Intelligence ===
ENABLE_PHASE4_HUMAN_LIKE=true
PHASE4_PERSONALITY_TYPE=caring_friend
PHASE4_CONVERSATION_MODE=adaptive
PHASE4_EMOTIONAL_INTELLIGENCE_LEVEL=high
PHASE4_RELATIONSHIP_AWARENESS=true
PHASE4_CONVERSATION_FLOW_PRIORITY=true
PHASE4_EMPATHETIC_LANGUAGE=true
PHASE4_MEMORY_PERSONAL_DETAILS=true

# === Phase 3 Memory Integration ===
PHASE3_MAX_MEMORIES=50

# === Semantic Clustering ===
SEMANTIC_CLUSTERING_MAX_MEMORIES=20
SEMANTIC_CLUSTERING_TIMEOUT=30

# === Embeddings ===
USE_EXTERNAL_EMBEDDINGS=false
LLM_EMBEDDING_API_URL=
LLM_EMBEDDING_API_KEY=
LLM_EMBEDDING_MODEL=text-embedding-3-small
LLM_LOCAL_EMBEDDING_MODEL=all-Mpnet-BASE-v2

# =======================================================
# EMOTION AI CONFIGURATION
# =======================================================

# === Local Emotion Analysis ===
ENABLE_VADER_EMOTION=true
ENABLE_ROBERTA_EMOTION=true
ROBERTA_EMOTION_MODEL=cardiffnlp/twitter-roberta-base-emotion-multilingual-latest
EMOTION_CACHE_SIZE=500
EMOTION_BATCH_SIZE=8

# === GPU Acceleration ===
USE_GPU=false

# =======================================================
# VOICE CONFIGURATION
# =======================================================

# === Voice Features ===
VOICE_AUTO_JOIN=false
VOICE_RESPONSE_ENABLED=true
VOICE_LISTENING_ENABLED=true
VOICE_STREAMING_ENABLED=true
VOICE_JOIN_ANNOUNCEMENTS=true

# === Voice Limits & Timing ===
VOICE_MAX_AUDIO_LENGTH=30
VOICE_MAX_RESPONSE_LENGTH=300
VOICE_RESPONSE_DELAY=1.0

# === Voice Connection Management ===
VOICE_KEEPALIVE_INTERVAL=300
VOICE_HEARTBEAT_INTERVAL=30
VOICE_MAX_RECONNECT_ATTEMPTS=3

# =======================================================
# BACKUP & MAINTENANCE
# =======================================================

# === Automatic Backups ===
AUTO_BACKUP_ENABLED=true
AUTO_BACKUP_INTERVAL_HOURS=24
BACKUP_RETENTION_COUNT=5
BACKUP_PATH=./backups

# =======================================================
# DEVELOPMENT & MONITORING
# =======================================================

# === Debug & Logging ===
DEBUG_MODE=false
LOG_LEVEL=INFO
PYTHONUNBUFFERED=1

# === Health Checks ===
HEALTH_CHECK_PORT=9090
HEALTH_CHECK_HOST=0.0.0.0

# === Environment Detection ===
CONTAINER_MODE=false
DOCKER_ENV=false
DEV_MODE=false

# =======================================================
# VISUAL EMOTION ANALYSIS - SPRINT 6
# =======================================================

# === Visual Emotion Analysis ===
ENABLE_VISUAL_EMOTION_ANALYSIS=true         # Enable visual emotion features
VISUAL_EMOTION_PROCESSING_MODE=auto          # auto/local/cloud
VISUAL_EMOTION_CONFIDENCE_THRESHOLD=0.6      # Minimum confidence for emotion detection
VISUAL_EMOTION_MAX_IMAGE_SIZE=10             # MB limit for image processing

# === Vision Model Configuration ===
VISION_MODEL_PROVIDER=openai                 # openai/anthropic/local
VISION_MODEL_NAME=gpt-4-vision-preview       # Cloud: gpt-4v, claude-3-vision
LOCAL_VISION_MODEL=llava-1.5-7b              # Local: llava, blip2, clip

# === Privacy and Storage ===
VISUAL_EMOTION_RETENTION_DAYS=30             # How long to keep visual emotion memories
VISUAL_EMOTION_PRIVACY_MODE=enhanced         # basic/enhanced/strict
STORE_VISUAL_EMOTIONS_LOCALLY=true           # Desktop mode: store in local DB only

# === Discord Integration ===
DISCORD_VISUAL_EMOTION_ENABLED=true          # Enable Discord image analysis
DISCORD_VISUAL_RESPONSE_ENABLED=true         # Generate responses to images
DISCORD_VISUAL_REACTION_ENABLED=true         # Add emoji reactions based on emotions

# =======================================================
# CLOUD PROVIDER EXAMPLES (UNCOMMENT TO USE)
# =======================================================

# === OpenAI ===
# LLM_CHAT_API_URL=https://api.openai.com/v1
# LLM_CHAT_API_KEY=your_openai_api_key
# LLM_CHAT_MODEL=gpt-4

# === OpenRouter ===
# LLM_CHAT_API_URL=https://openrouter.ai/api/v1
# LLM_CHAT_API_KEY=your_openrouter_api_key
# LLM_CHAT_MODEL=openai/gpt-4o

# === Ollama (Local) ===
# LLM_CHAT_API_URL=http://localhost:11434/v1
# LLM_CHAT_MODEL=phi3:mini

# === HuggingFace ===
# HUGGINGFACE_API_KEY=your_huggingface_api_key

# =======================================================
# ADVANCED CONFIGURATION
# =======================================================

# === Multi-Bot Mode ===
WHISPERENGINE_MODE=single_bot

# === Environment Override ===
ENVIRONMENT=development

# === Custom Paths ===
DOTENV_PATH=

# LLM Performance Settings
LLM_TEMPERATURE=0.7                         # Creativity 0.0-2.0
LLM_REQUEST_TIMEOUT=90                      # LM Studio can be slow
LLM_CONNECTION_TIMEOUT=10                   # Connection establishment timeout

# Token Limits - Optimized for large system prompts with emotional intelligence
LLM_MAX_TOKENS_CHAT=4096                   # Main chat response tokens
LLM_MAX_TOKENS_COMPLETION=1024              # Completion tokens
LLM_MAX_TOKENS_EMOTION=200                  # Emotion analysis tokens
LLM_MAX_TOKENS_FACT_EXTRACTION=500          # Fact extraction tokens
LLM_MAX_TOKENS_PERSONAL_INFO=400            # Personal info tokens
LLM_MAX_TOKENS_TRUST_DETECTION=300          # Trust detection tokens
LLM_MAX_TOKENS_USER_FACTS=400               # User facts tokens

# Vision Support (experimental)
LLM_SUPPORTS_VISION=false
LLM_VISION_MAX_IMAGES=5


# Message Security
MAX_SYSTEM_MESSAGE_LENGTH=                  # Auto-calculated
SECURITY_LOG_LEVEL=quiet

# =======================================================
# DATABASE CONFIGURATION
# =======================================================

# PostgreSQL Database Configuration (required)
# For Docker: use service name "postgres"
# For Native: use "localhost" 
POSTGRES_HOST=localhost                     # Use "postgres" for Docker mode
POSTGRES_PORT=5432
POSTGRES_DB=whisper_engine
POSTGRES_USER=bot_user
POSTGRES_PASSWORD=bot_password_change_me

# Connection pool settings
POSTGRES_MIN_CONNECTIONS=5
POSTGRES_MAX_CONNECTIONS=20
POSTGRES_PRIVACY_MIN_CONNECTIONS=3          # Privacy manager pool
POSTGRES_PRIVACY_MAX_CONNECTIONS=10         # Privacy manager pool

# Redis Configuration (required)
# For Docker: use service name "redis"
# For Native: use "localhost"
REDIS_HOST=localhost                        # Use "redis" for Docker mode
REDIS_PORT=6379
REDIS_DB=0
USE_REDIS_CACHE=true

# Redis cache settings
CONVERSATION_CACHE_TIMEOUT_MINUTES=15
CONVERSATION_CACHE_BOOTSTRAP_LIMIT=20
CONVERSATION_CACHE_MAX_LOCAL=50

# ChromaDB Configuration (required)
USE_CHROMADB_HTTP=true
# For Docker: use service name "chromadb"
# For Native: use "localhost"
CHROMADB_HOST=localhost                     # Use "chromadb" for Docker mode
CHROMADB_PORT=8000
CHROMADB_PATH=./chromadb_data
CHROMADB_COLLECTION_NAME=user_memories
CHROMADB_GLOBAL_COLLECTION_NAME=global_facts
ANONYMIZED_TELEMETRY=false

# Neo4j Graph Database (optional)
ENABLE_GRAPH_DATABASE=false
# For Docker: use service name "neo4j"
# For Native: use "localhost"
NEO4J_HOST=localhost                        # Use "neo4j" for Docker mode
NEO4J_PORT=7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=neo4j_password_change_me
NEO4J_DATABASE=neo4j

# Graph features
GRAPH_SYNC_MODE=async                       # Options: async, sync, disabled
FALLBACK_TO_EXISTING=true
EMOTION_GRAPH_SYNC_INTERVAL=10

# =======================================================
# MEMORY SYSTEM CONFIGURATION
# =======================================================

# Memory Features
ENABLE_AUTO_FACTS=true
ENABLE_GLOBAL_FACTS=true
ENABLE_EMOTIONS=true

# Memory Optimization Features (NEW)
ENABLE_MEMORY_SUMMARIZATION=true            # Intelligent conversation summarization
ENABLE_MEMORY_DEDUPLICATION=true            # Remove redundant memories
ENABLE_MEMORY_CLUSTERING=true               # Organize memories by topics
ENABLE_MEMORY_PRIORITIZATION=true           # Smart context ranking
MEMORY_OPTIMIZATION_INTERVAL=24             # Hours between optimization cycles

# Embedding Configuration
USE_EXTERNAL_EMBEDDINGS=false
# Embedding Model Selection
EMBEDDING_MODEL_NAME=text-embedding-nomic-embed-text-v1.5
FALLBACK_EMBEDDING_MODEL=all-mpnet-base-v2
LOAD_FALLBACK_EMBEDDING_MODELS=true

# Embedding Performance
EMBEDDING_BATCH_SIZE=100
EMBEDDING_MAX_RETRIES=3
EMBEDDING_RETRY_DELAY=1.0
EMBEDDING_MAX_CONCURRENT=5

# Backup System
AUTO_BACKUP_ENABLED=true
AUTO_BACKUP_INTERVAL_HOURS=24
BACKUP_RETENTION_COUNT=5
BACKUP_PATH=./backups

# =======================================================
# VOICE FEATURES
# =======================================================

# Voice System
VOICE_SUPPORT_ENABLED=true

# ElevenLabs API
ELEVENLABS_API_KEY=                         # Your ElevenLabs API key
ELEVENLABS_DEFAULT_VOICE_ID=ked1vRAQW5Sk9vhZC3vI # Updated default voice
ELEVENLABS_VOICE_STABILITY=0.5              # 0.0-1.0
ELEVENLABS_VOICE_SIMILARITY_BOOST=0.8       # 0.0-1.0
ELEVENLABS_VOICE_STYLE=0.0                  # 0.0-1.0, most natural
ELEVENLABS_USE_SPEAKER_BOOST=true

# Voice Behavior
VOICE_AUTO_JOIN=false
VOICE_RESPONSE_ENABLED=true
VOICE_LISTENING_ENABLED=true
VOICE_STREAMING_ENABLED=true
VOICE_MAX_RESPONSE_LENGTH=300               # characters
VOICE_MAX_AUDIO_LENGTH=30                   # seconds
VOICE_RESPONSE_DELAY=1.0                    # seconds

# Voice Connection Management
VOICE_JOIN_ANNOUNCEMENTS=true
VOICE_KEEPALIVE_INTERVAL=300                # 5 minutes
VOICE_HEARTBEAT_INTERVAL=30                 # seconds
VOICE_MAX_RECONNECT_ATTEMPTS=3
VOICE_RECONNECT_DELAY=5.0                   # seconds

# =======================================================
# JOB SCHEDULER & AUTOMATION
# =======================================================

# Job Scheduler Configuration
JOB_SCHEDULER_ENABLED=true
JOB_SCHEDULER_CHECK_INTERVAL_SECONDS=30

# Follow-up Message Configuration  
FOLLOW_UP_ENABLED=true
FOLLOW_UP_DEFAULT_DELAY_HOURS=48
FOLLOW_UP_MAX_PER_USER_PER_WEEK=2
FOLLOW_UP_MIN_HOURS_BETWEEN=24

# Data Cleanup Configuration
CLEANUP_ENABLED=true
CLEANUP_OLD_CONVERSATIONS_DAYS=30
CLEANUP_TEMP_FILES_HOURS=24
CLEANUP_FAILED_JOBS_DAYS=7

# =======================================================
# SYSTEM CONFIGURATION
# =======================================================

# Environment and Debugging
ENVIRONMENT=development
DEBUG_MODE=false
LOG_LEVEL=INFO
LOG_DIR=logs
LOG_APP_NAME=discord_bot

# Performance Settings
MAX_PROCESSING_TIME=60.0                    # seconds

# System Prompt File - Customize your AI's personality
# Default: Dream character from The Sandman series
BOT_SYSTEM_PROMPT_FILE=./prompts/default.md

# Choose from pre-built personality templates:
# BOT_SYSTEM_PROMPT_FILE=./prompts/empathetic_companion_template.md    # üíù Supportive friend
# BOT_SYSTEM_PROMPT_FILE=./prompts/professional_ai_template.md        # üëî Business assistant  
# BOT_SYSTEM_PROMPT_FILE=./prompts/casual_friend_template.md          # üòä Casual chat buddy
# BOT_SYSTEM_PROMPT_FILE=./prompts/character_ai_template.md           # üé≠ Roleplay characters
# BOT_SYSTEM_PROMPT_FILE=./prompts/adaptive_ai_template.md            # üß† Self-adapting AI
# BOT_SYSTEM_PROMPT_FILE=./prompts/dream_ai_enhanced.md               # ‚ú® Enhanced Dream character

# Or create your own custom personality file in the prompts directory:
# BOT_SYSTEM_PROMPT_FILE=./prompts/my_custom_personality.md

# File and Image Processing
TEMP_IMAGES_DIR=temp_images

# NLP Configuration (advanced)
NLP_DEPLOYMENT_MODE=native_integrated
NLP_SERVICE_HOST=localhost
NLP_SERVICE_PORT=8080
NLP_TIMEOUT_SECONDS=30
NLP_SPACY_MODEL=en_core_web_lg

# Container Detection (auto-detected)
DOCKER_CONTAINER=                           # Auto-detected by environment
ENV_MODE=                                   # Explicit environment mode override
CONTAINER_MODE=                             # Container mode indicator
DEV_MODE=                                   # Development mode indicator

# External API Keys (for external services)
OPENAI_API_KEY=                             # OpenAI API key
OPENROUTER_API_KEY=                         # OpenRouter API key  
HUGGINGFACE_API_KEY=                        # HuggingFace API key

# ====================================
# üß† AI Features Configuration
# ====================================
# All AI features are ENABLED BY DEFAULT for full capabilities
# Use performance tuning parameters to optimize rather than disable features

# Phase 1: Basic LLM Responses + Context Awareness
ENABLE_BASIC_AI=true                        # Core AI functionality (always enabled)

# Phase 2: Emotional Intelligence System 
ENABLE_EMOTIONAL_INTELLIGENCE=true         # Multi-source emotion analysis (96-98% accuracy)
EMOTION_API_TIMEOUT=5                       # External emotion API timeout (seconds)
EMOTION_CACHE_SIZE=1000                     # Emotional state cache entries
EMOTION_CONFIDENCE_THRESHOLD=0.7            # Minimum confidence for emotion detection

# Phase 3: Multi-Dimensional Memory Networks
ENABLE_PHASE3_MEMORY=true                   # Advanced semantic memory (ChromaDB + Redis)
MEMORY_RETENTION_DAYS=30                    # Memory retention period
MEMORY_MAX_ENTRIES=10000                    # Maximum memory entries per user
ENABLE_MEMORY_COMPRESSION=true              # Compress old memories for efficiency

# Phase 4: Human-Like Conversation Adaptation
ENABLE_PHASE4_INTELLIGENCE=true             # Advanced conversation adaptation
PERSONALITY_ADAPTATION_ENABLED=true         # Dynamic personality adjustment
CONVERSATION_CONTEXT_DEPTH=10               # Conversation history depth for adaptation

# Performance Optimization (tune for your system)
ENABLE_PROMPT_OPTIMIZATION=true             # Use optimized prompts for bundled models
OPTIMIZED_PROMPT_MODE=auto                  # auto|always|never - automatic selection
MAX_CONCURRENT_AI_OPERATIONS=3              # Limit concurrent AI operations
AI_RESPONSE_TIMEOUT=30                      # AI response timeout (seconds)
ENABLE_AI_CACHING=true                      # Cache AI responses for performance

# Memory System Configuration
USE_REDIS_CACHE=true                        # Redis for conversation caching
ENABLE_GRAPH_DATABASE=false                 # Neo4j for relationship mapping (optional)
CHROMA_BATCH_SIZE=100                       # ChromaDB batch processing size
MEMORY_SEARCH_LIMIT=20                      # Maximum memory search results
