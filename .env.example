# --- Application ---
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=DEBUG

# --- LLM Configuration ---
# Options: openai, openrouter, ollama, lmstudio
LLM_PROVIDER=openrouter
LLM_API_KEY=sk-your-api-key-here
LLM_MODEL_NAME=gpt-4o
# LLM_BASE_URL=https://openrouter.ai/api/v1  # For OpenRouter
# LLM_BASE_URL=http://localhost:11434/v1     # For Ollama
# LLM_BASE_URL=http://localhost:1234/v1      # For LM Studio

# --- Router LLM Configuration (Optional) ---
# Use a faster/cheaper model for tool selection (e.g. gpt-4o-mini, local model)
# ROUTER_LLM_PROVIDER=openai
# ROUTER_LLM_API_KEY=sk-your-router-api-key
# ROUTER_LLM_MODEL_NAME=gpt-4o-mini
# ROUTER_LLM_BASE_URL=

# --- Reflective Mode Configuration (Optional) ---
# Deep thinking ReAct loop for complex questions (makes classifier call + multi-step reasoning)
# When enabled, makes 1 extra LLM call to classify message complexity
# Complex messages trigger multi-step reasoning (3-10 additional LLM calls)
# Cost: ~$0.02-0.03 per complex query vs $0.001-0.005 for simple queries
ENABLE_REFLECTIVE_MODE=false
REFLECTIVE_LLM_PROVIDER=openrouter
REFLECTIVE_LLM_API_KEY=sk-your-reflective-api-key
REFLECTIVE_LLM_MODEL_NAME=anthropic/claude-3.7-sonnet
REFLECTIVE_LLM_BASE_URL=https://openrouter.ai/api/v1
REFLECTIVE_MAX_STEPS=5
REFLECTIVE_MEMORY_RESULT_LIMIT=3

# --- Discord ---
DISCORD_TOKEN=your-discord-bot-token-here
DISCORD_BOT_NAME=your-bot-name

# --- Databases ---
POSTGRES_URL=postgresql://whisper:password@localhost:5432/whisperengine_v2
QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=your-qdrant-api-key
NEO4J_URL=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
INFLUXDB_URL=http://localhost:8086
INFLUXDB_TOKEN=my-super-secret-auth-token
INFLUXDB_ORG=whisperengine
INFLUXDB_BUCKET=metrics

# --- API ---
API_HOST=0.0.0.0
API_PORT=8000

# --- Voice (ElevenLabs) ---
# ELEVENLABS_API_KEY=your-elevenlabs-api-key
# ELEVENLABS_VOICE_ID=your-voice-id
# ELEVENLABS_MODEL_ID=eleven_monolingual_v1

# --- Feature Flags (Resource Management) ---
# Enable vision/image analysis (requires LLM with vision capabilities like GPT-4V, Claude 3)
LLM_SUPPORTS_VISION=true

# Enable automatic fact extraction from messages (makes 1 LLM call per message)
# Extracts facts like name, location, preferences and stores in Knowledge Graph
ENABLE_RUNTIME_FACT_EXTRACTION=true

# Enable automatic preference extraction from messages (makes 1 LLM call per message)
# Detects user preferences like "be concise", "use emojis", "call me Captain"
ENABLE_PREFERENCE_EXTRACTION=true

# Enable proactive messaging (bot reaches out to users periodically)
# Requires scheduler and activity analysis
ENABLE_PROACTIVE_MESSAGING=false

# Log full prompts and responses to logs/prompts/ for debugging
# Useful for debugging but can generate large log files
ENABLE_PROMPT_LOGGING=true
