# Production Docker Compose Configuration
# Optimized for production deployment with external services

services:
  whisperengine-bot:
    build:
      context: .
      dockerfile: docker/Dockerfile.multi-stage
      target: production
    image: whisperengine-bot:${VERSION:-latest}
    container_name: whisperengine-bot
    restart: unless-stopped
    
    # Environment configuration
    env_file:
      - .env             # Local secrets and overrides
    environment:
      # Production overrides
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ENV_MODE=production
      # CDL Character Configuration
      - CDL_DEFAULT_CHARACTER=${CDL_DEFAULT_CHARACTER:-characters/default_assistant.json}
      
      # LLM Configuration - OPTIMIZED (Single API endpoint)
      - LLM_CHAT_API_URL=https://openrouter.ai/api/v1
      - LLM_MODEL_NAME=openai/gpt-4o
      - LLM_CHAT_MODEL=openai/gpt-4o
      
      # Local AI Systems - No additional APIs needed
      - USE_LOCAL_EMOTION_ANALYSIS=true
      - USE_LOCAL_FACT_EXTRACTION=true
      - DISABLE_EXTERNAL_EMOTION_API=true
      - DISABLE_REDUNDANT_FACT_EXTRACTION=true
      
      # Single embedding model (local)
      - LLM_LOCAL_EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
      
      - DEBUG_MODE=false
      - PYTHONUNBUFFERED=1
      
    # Expose health check port for container orchestration
    ports:
      - "9090:9090"  # Health check endpoint
      
    # Production-optimized resource limits for high-throughput multi-user scenarios
    deploy:
      resources:
        limits:
          memory: 4G          # Support for high concurrent user load and memory caching
          cpus: '4.0'         # Adequate cores for 12 thread workers + 6 process workers
        reservations:
          memory: 2G          # Reliable baseline for production stability
          cpus: '2.0'         # Ensure minimum cores always available
    
    # Health check - use the built-in health endpoint
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9090/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    # Persistent volumes - Bot application data only
    volumes:
      # Application-specific data (NOT datastore data)
      - bot_backups:/app/backups
      - bot_privacy:/app/privacy_data
      - bot_temp:/app/temp_images
      - bot_logs:/app/logs
      # Configuration files (read-only)
      - ./characters:/app/characters:ro
      - ./config:/app/config:ro
      
    # Network
    networks:
      - bot_network
      
    # Dependencies
    depends_on:
      - redis
      - postgres
      - qdrant

  # Redis for caching
  redis:
    image: redis:7-alpine
    container_name: whisperengine-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - bot_network
    # Production resource limits for Redis
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # PostgreSQL for persistent data
  postgres:
    image: postgres:16-alpine
    container_name: whisperengine-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-whisper_engine}
      POSTGRES_USER: ${POSTGRES_USER:-bot_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init_postgres.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - bot_network
    # Production resource limits for PostgreSQL
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # Qdrant for vector storage
  qdrant:
    image: qdrant/qdrant:v1.15.4
    container_name: whisperengine-qdrant
    restart: unless-stopped
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__LOG_LEVEL=INFO
    volumes:
      - ./data/qdrant:/qdrant/storage   # Direct bind mount for easier backup access
    networks:
      - bot_network
    # Production resource limits for Qdrant
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    
    # Health check for container orchestration
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s



# Networks
networks:
  bot_network:
    driver: bridge
    name: whisperengine-network

# Volumes - Properly separated by service responsibility
volumes:
  # Bot application volumes (NOT datastore data)
  bot_backups:
    name: whisperengine-backups
    driver: local
  bot_privacy:
    name: whisperengine-privacy
    driver: local
  bot_temp:
    name: whisperengine-temp
    driver: local
  bot_logs:
    name: whisperengine-logs
    driver: local
  
  # Datastore volumes (managed by their respective services)
  redis_data:
    name: whisperengine-redis
    driver: local
  postgres_data:
    name: whisperengine-postgres
    driver: local
  qdrant_data:
    name: whisperengine-qdrant
    driver: local

