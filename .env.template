# =======================================================
# WhisperEngine Multi-Bot Environment Template
# =======================================================
# Copy this file for each bot: .env.botname
# Customize the bot-specific sections below
# =======================================================

# =======================================================
# üö® REQUIRED: Bot Identity (MUST BE UNIQUE)
# =======================================================
DISCORD_BOT_TOKEN=YOUR_BOT_TOKEN_HERE
DISCORD_BOT_NAME=YourBotName  # CRITICAL: Must match database character name
HEALTH_CHECK_PORT=9091  # Increment: 9091, 9092, 9093...

# =======================================================
# üë• OPTIONAL: Bot-Specific Administration
# =======================================================
ADMIN_USER_IDS=  # Could be different per bot
LOG_LEVEL=INFO  # Could use DEBUG for specific bots

# =======================================================
# üß† OPTIONAL: Bot-Specific AI Configuration
# =======================================================
# Different characters could use different models
LLM_CHAT_MODEL=x-ai/grok-4-fast:free  # Elena: scientific model, Marcus: research model

# ==============================================================================
# FACT & PREFERENCE EXTRACTION CONFIGURATION
# ==============================================================================

# Runtime Fact Extraction (optional - default: true)
ENABLE_RUNTIME_FACT_EXTRACTION=true

# Runtime Preference Extraction (optional - default: true)
ENABLE_RUNTIME_PREFERENCE_EXTRACTION=true


# RoBERTa Emotion Model Configuration
ROBERTA_EMOTION_MODEL_NAME=cardiffnlp/twitter-roberta-base-emotion-multilabel-latest

# (Engagement engine configuration removed: not referenced by Python runtime)

# =======================================================
# ‚ö° CONCURRENT CONVERSATION MANAGEMENT (Always Enabled)
# =======================================================
# ConcurrentConversationManager is now required for optimal performance
MAX_WORKER_THREADS=0                           # Thread pool size (0 = auto-detect)
MAX_WORKER_PROCESSES=0                         # Process pool size (0 = auto-detect)

# =======================================================
# üöÄ STARTUP RELIABILITY (Prevent Race Conditions)
# =======================================================
# (Startup delay configuration removed: not referenced by Python runtime)

# =======================================================
# üé§ OPTIONAL: Bot-Specific Voice Configuration  
# =======================================================
VOICE_SERVICE_TYPE=discord_elevenlabs  # Could vary per character
# Voice text channel matching: bot responds ONLY in text channels that correspond to the voice channel
# Set VOICE_USE_PATTERN_FALLBACK=true to enable broader pattern matching as fallback
VOICE_USE_PATTERN_FALLBACK=false  # Precise matching by default
VOICE_TEXT_CHANNELS=voice,chat,general,bot  # Only used if pattern fallback enabled
ELEVENLABS_API_KEY=your_key_here  # Different voices/accounts per bot

# =======================================================
# ü§ù SHARED: Infrastructure (SAME FOR ALL BOTS)
# =======================================================
# LLM API (usually shared) - Default to local LM Studio
LLM_CLIENT_TYPE=lmstudio
LLM_CHAT_API_URL=http://host.docker.internal:1234/v1
LLM_CHAT_API_KEY=
ENABLE_PROMPT_COMPONENT_CHARACTER_IDENTITY=true
ENABLE_PROMPT_COMPONENT_CHARACTER_MODE=false
ENABLE_PROMPT_COMPONENT_CHARACTER_BACKSTORY=false
ENABLE_PROMPT_COMPONENT_CHARACTER_PRINCIPLES=false
ENABLE_PROMPT_COMPONENT_AI_IDENTITY_GUIDANCE=false
ENABLE_PROMPT_COMPONENT_CHARACTER_COMMUNICATION_PATTERNS=false
ENABLE_PROMPT_COMPONENT_TEMPORAL_AWARENESS=true
ENABLE_PROMPT_COMPONENT_USER_PERSONALITY=false
ENABLE_PROMPT_COMPONENT_CHARACTER_PERSONALITY=false
ENABLE_PROMPT_COMPONENT_CHARACTER_LEARNING=false
ENABLE_PROMPT_COMPONENT_CHARACTER_VOICE=true
ENABLE_PROMPT_COMPONENT_CHARACTER_RELATIONSHIPS=false
ENABLE_PROMPT_COMPONENT_EMOTIONAL_TRIGGERS=false
ENABLE_PROMPT_COMPONENT_EPISODIC_MEMORIES=true
ENABLE_PROMPT_COMPONENT_CONVERSATION_SUMMARY=true
ENABLE_PROMPT_COMPONENT_UNIFIED_INTELLIGENCE=false
ENABLE_PROMPT_COMPONENT_EMOTIONAL_CONTEXT=false
ENABLE_PROMPT_COMPONENT_KNOWLEDGE_CONTEXT=false
ENABLE_PROMPT_COMPONENT_RESPONSE_STYLE=true
ENABLE_PROMPT_COMPONENT_CORE_SYSTEM=false
ENABLE_PROMPT_COMPONENT_TIME_CONTEXT=false
ENABLE_PROMPT_COMPONENT_ATTACHMENT_GUARD=false
ENABLE_PROMPT_COMPONENT_MEMORY=true
ENABLE_PROMPT_COMPONENT_CONVERSATION_FLOW=false
ENABLE_PROMPT_COMPONENT_USER_FACTS=true
ENABLE_PROMPT_COMPONENT_RECENT_CONTEXT=false
ENABLE_PROMPT_COMPONENT_GUIDANCE=false
ENABLE_PROMPT_COMPONENT_COMMUNICATION_STYLE=false
ENABLE_PROMPT_COMPONENT_AI_INTELLIGENCE=false
ENABLE_PROMPT_COMPONENT_EMOTION_CONTEXT=false
ENABLE_PROMPT_COMPONENT_RELATIONSHIP_STATE=false
ENABLE_PROMPT_COMPONENT_CONFIDENCE_GUIDANCE=false
ENABLE_PROMPT_COMPONENT_TRENDWISE_ADAPTATION=false
ENABLE_PROMPT_COMPONENT_LEARNING_INSIGHTS=false
ENABLE_PROMPT_COMPONENT_ANTI_HALLUCINATION=false
ENABLE_PROMPT_COMPONENT_RESPONSE_CONSTRAINTS=false
ENABLE_PROMPT_COMPONENT_CUSTOM=false

# Support for vision/image analysis
LLM_SUPPORTS_VISION=true
LLM_VISION_MAX_IMAGES=5

# Database connections (shared infrastructure)
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=whisperengine
POSTGRES_USER=whisperengine
POSTGRES_PASSWORD=whisperengine_password
# (PostgreSQL pool size envs removed: not referenced by Python runtime)

REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

QDRANT_HOST=qdrant
QDRANT_PORT=6333
# (QDRANT_GRPC_PORT removed: not referenced by Python runtime)

# InfluxDB (Time-series data for temporal intelligence)
INFLUXDB_URL=http://influxdb:8086
INFLUXDB_TOKEN=whisperengine-fidelity-first-metrics-token
INFLUXDB_ORG=whisperengine
INFLUXDB_BUCKET=performance_metrics

# Memory system (shared)
MEMORY_SYSTEM_TYPE=vector
VECTOR_DIMENSION=384
# Use sentence-transformers/all-MiniLM-L6-v2 - 384 dims, best quality, excellent speed
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Model Cache Configuration (Pre-downloaded models)
MODEL_CACHE_DIR=/app/models
DISABLE_MODEL_DOWNLOAD=true

# Emoji Intelligence Configuration
EMOJI_BASE_THRESHOLD=0.4
EMOJI_NEW_USER_THRESHOLD=0.3

# Global feature flags (usually same)
DEBUG_MODE=false
PYTHONUNBUFFERED=1

# Prompt Logging Configuration
# WARNING: Prompt logging writes EVERY conversation to logs/prompts/ directory
# This includes full conversation context and LLM responses for debugging
# DISABLE in production to reduce disk I/O and protect user privacy
ENABLE_PROMPT_LOGGING=false

# =======================================================
# SECURITY: Mystical Symbol Detection
# =======================================================
# Silently ignores messages with high density of mystical/esoteric symbols
# or ritualistic math patterns (spam/unwanted content)
# Default: false (disabled) - Set to 'true' to enable filtering
# Thresholds: 20% symbol density + 3 minimum symbols, or ritualistic math patterns
ENABLE_MYSTICAL_SYMBOL_FILTER=false

# =======================================================
# ADVANCED: Character-Specific Customizations
# =======================================================
# You could even have character-specific settings like:

# Elena (Marine Biologist) - More scientific/cautious
# LLM_CHAT_MODEL=microsoft/wizardlm-2-8x22b  # More analytical model
# ENABLE_PROACTIVE_ENGAGEMENT=false  # More reserved personality

# Marcus (AI Researcher) - More experimental  
# LLM_CHAT_MODEL=anthropic/claude-3.5-sonnet  # Research-focused model
# ENABLE_PROACTIVE_ENGAGEMENT=true  # More engaging personality

# Dream (Mystical) - More creative
# LLM_CHAT_MODEL=openai/gpt-4-turbo  # More creative model
# ENGAGEMENT_ENGINE_TYPE=full  # Highly engaging

# =======================================================
# ü§ñ ML SHADOW MODE: Response Strategy Optimization
# =======================================================
# Enables ML-based response strategy prediction (runs in parallel with existing logic)
# Default: true (enabled for production testing, zero user impact)
# ML model compares predictions against current strategy selection for validation
# Logged to InfluxDB ml_shadow_mode measurement for A/B testing analysis
ENABLE_ML_SHADOW_MODE=true