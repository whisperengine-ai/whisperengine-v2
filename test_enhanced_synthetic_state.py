#!/usr/bin/env python3
"""
Test Enhanced Synthetic Conversation State Management

This demonstrates how the synthetic conversation generator maintains full conversational 
state across all turns in a test scenario, enabling contextually aware responses that 
build upon the conversation history.

Author: WhisperEngine AI Team
Created: October 9, 2025
Purpose: Validate enhanced state-aware synthetic testing
"""

import asyncio
import json
from datetime import datetime
from synthetic_conversation_generator import (
    SyntheticConversationGenerator, 
    SyntheticUser, 
    UserPersona, 
    ConversationType
)

async def test_enhanced_conversation_state():
    """Test enhanced conversation state management with full turn-by-turn tracking"""
    
    print("ğŸ”¬ Testing Enhanced Synthetic Conversation State Management")
    print("=" * 60)
    
    # Create generator (disable LLM for predictable testing)
    generator = SyntheticConversationGenerator({}, use_llm=False)
    
    # Create analytical test user
    test_user = SyntheticUser(
        user_id='analytical_tester_001',
        name='Dr. Sarah Chen',
        persona=UserPersona.ANALYTICAL_THINKER,
        interests=['machine learning', 'data analysis', 'research methodology'],
        emotional_baseline={'curiosity': 0.8, 'analytical': 0.9, 'skepticism': 0.3},
        conversation_style='precise_scientific',
        memory_details={'research_focus': 'AI evaluation', 'experience_level': 'expert'},
        relationship_goals=['validate_systems', 'extract_insights', 'test_capabilities']
    )
    
    print(f"ğŸ‘¤ Test User: {test_user.name} ({test_user.persona.value})")
    print(f"ğŸ¯ Interests: {', '.join(test_user.interests)}")
    print(f"ğŸ’­ Goals: {', '.join(test_user.relationship_goals)}")
    print()
    
    # Test conversation type: Character Vector Episodic Intelligence
    conversation_type = ConversationType.CHARACTER_VECTOR_EPISODIC_INTELLIGENCE
    conversation_id = f"test_{test_user.user_id}_elena_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    print(f"ğŸ§ª Test Scenario: {conversation_type.value}")
    print(f"ğŸ†” Conversation ID: {conversation_id}")
    print()
    
    # Initialize conversation state
    generator._initialize_conversation_state(conversation_id, test_user, 'elena', conversation_type)
    initial_state = generator.conversation_state[conversation_id]
    
    print("ğŸ“Š INITIAL CONVERSATION STATE:")
    print(f"  ğŸ­ Conversation Arc: {initial_state['conversation_arc']}")
    print(f"  ğŸ¯ Planned Phases: {initial_state['conversation_arc']['phases']}")
    print(f"  ğŸ“‹ Goals: {initial_state['conversation_arc']['goals']}")
    print(f"  ğŸ’« Relationship Baseline: {initial_state['relationship_evolution']}")
    print()
    
    # Simulate multi-turn conversation with state evolution
    test_exchanges = [
        {
            "turn": 1,
            "user_message": "Tell me about a time when you learned something important from our past conversations",
            "bot_response": "I remember when you explained your research methodology for evaluating AI systems. That conversation taught me how important systematic testing is for understanding AI behavior patterns.",
            "metadata": {
                "user_emotion": {"primary_emotion": "curiosity"},
                "memory_stored": True,
                "user_facts": {"research_focus": "AI evaluation", "methodology": "systematic"},
                "relationship_metrics": {"trust": 0.6, "affection": 0.5, "attunement": 0.7}
            }
        },
        {
            "turn": 2,  
            "user_message": "That's exactly the kind of episodic learning I'm testing for. Can you elaborate on how that specific memory shaped your understanding?",
            "bot_response": "That memory created a framework for how I approach scientific discussions. When we talk about research now, I automatically consider methodology, validation, and systematic approaches because of what you taught me.",
            "metadata": {
                "user_emotion": {"primary_emotion": "analytical"},
                "memory_stored": True,
                "user_facts": {"teaching_style": "systematic", "expertise": "research_methodology"},
                "relationship_metrics": {"trust": 0.7, "affection": 0.6, "attunement": 0.8}
            }
        },
        {
            "turn": 3,
            "user_message": "Excellent! Now I want to test your meta-cognition. How has your ability to access and apply these episodic memories evolved over time?",
            "bot_response": "I've noticed my recall has become more contextual and interconnected. Early conversations felt isolated, but now I can see patterns across our discussions and apply insights from one conversation to enhance another.",
            "metadata": {
                "user_emotion": {"primary_emotion": "satisfaction"},
                "memory_stored": True,
                "user_facts": {"testing_focus": "meta-cognition", "interest": "memory_evolution"},
                "relationship_metrics": {"trust": 0.8, "affection": 0.7, "attunement": 0.9}
            }
        }
    ]
    
    print("ğŸ”„ CONVERSATION SIMULATION WITH STATE TRACKING:")
    print()
    
    for exchange in test_exchanges:
        turn = exchange["turn"]
        user_msg = exchange["user_message"]
        bot_response = exchange["bot_response"]
        metadata = exchange["metadata"]
        
        print(f"TURN {turn}:")
        print(f"  ğŸ‘¤ User: {user_msg}")
        print(f"  ğŸ¤– Bot:  {bot_response}")
        
        # Update conversation state
        generator._update_conversation_state(conversation_id, turn, user_msg, bot_response, metadata)
        
        # Get current state after update
        current_state = generator.conversation_state[conversation_id]
        current_phase = generator._get_conversation_phase(conversation_id)
        
        print(f"  ğŸ“Š STATE UPDATE:")
        print(f"    ğŸ”„ Phase: {current_phase}")
        print(f"    ğŸ“š Topics: {current_state['topics_discussed']}")
        print(f"    ğŸ˜Š Emotions: {current_state['emotions_expressed']}")
        print(f"    â­ Key Moments: {len(current_state['key_moments'])}")
        print(f"    ğŸ“‹ Facts: {len(current_state['established_facts'])}")
        print(f"    ğŸ’– Relationship: Trust={current_state['relationship_evolution']['trust']:.1f}, Rapport={current_state['relationship_evolution']['rapport']:.1f}, Understanding={current_state['relationship_evolution']['understanding']:.1f}")
        print()
    
    # Show final conversation state summary
    final_state = generator.conversation_state[conversation_id]
    print("ğŸ“ˆ FINAL CONVERSATION STATE SUMMARY:")
    print("=" * 40)
    print(f"ğŸ¯ Total Turns: {final_state['turn_count']}")
    print(f"ğŸ“š Topics Discussed: {set(final_state['topics_discussed'])}")
    print(f"ğŸ˜Š Emotional Journey: {' â†’ '.join(final_state['emotions_expressed'])}")
    print(f"â­ Key Moments: {len(final_state['key_moments'])}")
    print(f"ğŸ“‹ Established Facts:")
    for fact in final_state['established_facts']:
        print(f"   - {fact['key']}: {fact['value']} (Turn {fact['established_turn']})")
    print(f"ğŸ’– Relationship Evolution:")
    print(f"   - Trust: 0.5 â†’ {final_state['relationship_evolution']['trust']:.1f}")
    print(f"   - Rapport: 0.5 â†’ {final_state['relationship_evolution']['rapport']:.1f}")  
    print(f"   - Understanding: 0.5 â†’ {final_state['relationship_evolution']['understanding']:.1f}")
    print()
    
    # Test LLM-enhanced message generation with state context
    print("ğŸ§  TESTING STATE-AWARE MESSAGE GENERATION:")
    print("=" * 45)
    
    # Create mock conversation history for LLM context
    conversation_history = []
    for exchange in test_exchanges:
        conversation_history.append({
            "turn": exchange["turn"],
            "user_message": exchange["user_message"],
            "bot_response": exchange["bot_response"],
            "user_emotion": exchange["metadata"]["user_emotion"],
            "conversation_phase": generator._get_conversation_phase(conversation_id),
            "conversation_state": final_state.copy()
        })
    
    # Generate next message with full state context (template-based since LLM disabled)
    next_message = await generator._generate_follow_up_message(
        test_user,
        "I've noticed my recall has become more contextual and interconnected...",
        ["memory", "learning", "evolution"],
        ["satisfaction", "analytical"],
        conversation_history=conversation_history,
        conversation_id=conversation_id
    )
    
    print(f"ğŸ—£ï¸ Generated Next Message: {next_message}")
    print()
    print("âœ… STATE-AWARE SYNTHETIC CONVERSATION SYSTEM VALIDATED!")
    print()
    print("ğŸ¯ KEY CAPABILITIES DEMONSTRATED:")
    print("  âœ… Full conversation state tracking across all turns")
    print("  âœ… Conversation arc planning and phase progression")
    print("  âœ… Relationship evolution tracking")
    print("  âœ… Established facts accumulation")
    print("  âœ… Emotional journey mapping")
    print("  âœ… Context-aware message generation")
    print("  âœ… Enhanced metadata integration")
    print()
    print("ğŸ”¬ TESTING IMPACT:")
    print("  ğŸ¯ Synthetic users now maintain realistic conversational context")
    print("  ğŸ“Š Full conversation state enables sophisticated test scenarios")
    print("  ğŸ§  LLM-enhanced generation produces contextually aware responses")
    print("  ğŸ”„ Multi-turn test scenarios reflect authentic human conversation patterns")
    
    return True

if __name__ == "__main__":
    result = asyncio.run(test_enhanced_conversation_state())
    print(f"\nğŸ† Test Result: {'SUCCESS' if result else 'FAILED'}")