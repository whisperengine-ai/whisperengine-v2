# ğŸš€ Message Pipeline Quick Reference Card

**Print this! Keep it handy!**

---

## ğŸ“Š THE FULL PIPELINE (23+ ACTUAL PHASES)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE    â”‚ NAME                                    â”‚ TIME     â”‚ TYPE   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0        â”‚ Initialize                              â”‚ ~1ms     â”‚ Setup  â”‚
â”‚ 1        â”‚ Security Validation                     â”‚ 5-10ms   â”‚ Serial â”‚
â”‚ 1.5      â”‚ Chronological Ordering (FIXED)          â”‚ 0ms      â”‚ No-op  â”‚
â”‚ 2        â”‚ Name Detection (DISABLED)               â”‚ 0ms      â”‚ No-op  â”‚
â”‚ 2.25     â”‚ Memory Summary Detection                â”‚ 50-100ms â”‚ Cond   â”‚
â”‚ 2.5      â”‚ Workflow Detection & Transactions       â”‚ 30-50ms  â”‚ Serial â”‚
â”‚ 2.75     â”‚ Early Emotion + NLP Cache + Stance      â”‚ 150-250msâ”‚ Serial â”‚
â”‚ 2.8      â”‚ Strategic Intelligence Cache            â”‚ 10-50ms  â”‚ Serial â”‚
â”‚ 2   âš™ï¸   â”‚ AI Enrichment (RoBERTa, Facts)          â”‚ 100-200msâ”‚ PARA   â”‚
â”‚ 3        â”‚ Memory Retrieval (Qdrant)               â”‚ 20-50ms  â”‚ Serial â”‚
â”‚ 4        â”‚ Context Building (PromptAsm)            â”‚ 50-100ms â”‚ Serial â”‚
â”‚ 4.5  â­  â”‚ 7 Strategic Intelligence Engines        â”‚ 200-400msâ”‚ PARA   â”‚
â”‚ 5        â”‚ Structured Prompt Assembly              â”‚ 50-100ms â”‚ Serial â”‚
â”‚ 5.5      â”‚ Enhanced Context with AI Intelligence   â”‚ 20-50ms  â”‚ Serial â”‚
â”‚ 6        â”‚ CDL Character Integration               â”‚ 30-50ms  â”‚ Serial â”‚
â”‚ 7   ğŸ–¼ï¸   â”‚ Image Processing (if needed)            â”‚ 0-2000ms â”‚ Opt    â”‚
â”‚ 6.5      â”‚ Bot Emotional State (REMOVED)           â”‚ â”€â”€â”€â”€â”€    â”‚ Depr   â”‚
â”‚ 6.7  ğŸ’•  â”‚ Adaptive Learning Enrichment            â”‚ 50-150ms â”‚ Serial â”‚
â”‚ 6.9  ğŸ”§  â”‚ Hybrid Query Routing & Tools (opt)      â”‚ 0-200ms  â”‚ Opt    â”‚
â”‚ 8   ğŸ¤–âš ï¸ â”‚ LLM Response Generation                 â”‚ 1-5s âŒ  â”‚ Serial â”‚
â”‚ 8.5  ğŸ­  â”‚ Bot Emotion Analysis                    â”‚ 50-100ms â”‚ Serial â”‚
â”‚ 8.6  ğŸ›¡ï¸  â”‚ Enhanced AI Ethics Monitoring           â”‚ 10-20ms  â”‚ Serial â”‚
â”‚ 8.7  âœ¨  â”‚ Intelligent Emoji Decoration            â”‚ 20-50ms  â”‚ Serial â”‚
â”‚ 9        â”‚ Response Validation & Sanitization      â”‚ 5-10ms   â”‚ Serial â”‚
â”‚ 10  ğŸ’¾âš¡ â”‚ Memory & Knowledge Storage              â”‚ 50-150ms â”‚ PARA+NBâ”‚
â”‚ 10a      â”‚  â”œâ”€ Qdrant Vector Memory                â”‚ 20-40ms  â”‚ Async  â”‚
â”‚ 10b      â”‚  â”œâ”€ PostgreSQL Facts                    â”‚ 10-20ms  â”‚ Async  â”‚
â”‚ 10c      â”‚  â”œâ”€ PostgreSQL Preferences              â”‚ 5-10ms   â”‚ Async  â”‚
â”‚ 10d      â”‚  â””â”€ InfluxDB Temporal Recording         â”‚ 5-15ms   â”‚ Async  â”‚
â”‚ 11  ğŸ§    â”‚ Learning Orchestration                  â”‚ 20-50ms  â”‚ Serial â”‚
â”‚ 12  ğŸ’•   â”‚ Relationship Evolution                  â”‚ 20-40ms  â”‚ Serial â”‚
â”‚ 13  ğŸ“¦   â”‚ Metadata & Response Return              â”‚ 1-2ms    â”‚ Serial â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš™ï¸  = Parallelized (async gather)
ğŸ¤–âš ï¸ = Bottleneck (70-90% of total time!)
ğŸ’¾âš¡ = Non-blocking (fire-and-forget async, Phase 10a-10d parallel)
â­ = MAJOR: 7-engine strategic system (NEW!)
```

---

## ğŸ¯ THREE GOLDEN RULES

**Rule 1: RoBERTa is EVERYWHERE** ğŸ­
- Phase 2.75: Early emotion analysis (150-250ms)
- Phase 2 (parallel): User message emotion (50-100ms) 
- Phase 8.5: Bot response emotion (50-100ms)
- 12+ metadata fields stored with EVERY memory
- **NEVER use keyword matching!** (use stored emotion data)

**Rule 2: PostgreSQL is the SOURCE OF TRUTH** ğŸ“Š
- **NOT** in Qdrant (that's for conversations only)
- Facts: `user_fact_relationships` + `fact_entities` (Phase 10b)
- Preferences: `universal_users.preferences` (JSONB, Phase 10c)
- Relationships: `relationship_metrics` (trust/affection/attunement)
- Character CDL: 50+ `character_*` tables
- Strategic cache: Phase 4.5 engines

**Rule 3: Three Summary Systems** ğŸ“
- **Real-Time (5-20ms)**: Fast, lossy, no LLM (Phase 3)
- **Background (2-5s)**: High-quality, LLM, PostgreSQL storage (enrichment worker)
- **Advanced (500ms-1s)**: Balanced, optional real-time

---

## ğŸ”„ DATA STORAGE DECISION TREE

```
Is it a conversation pair?
  YES â†’ Qdrant (Phase 10a)
        Vectors (content/emotion/semantic) + RoBERTa metadata
  NO â†’ Is it a fact about user?
       YES â†’ PostgreSQL fact_relationships (Phase 10b)
             Entity type, relationship, confidence
       NO â†’ Is it a preference?
            YES â†’ PostgreSQL preferences (Phase 10c)
                  JSONB with confidence
            NO â†’ Is it a time-series metric?
                 YES â†’ InfluxDB (Phase 10d)
                       Timestamp, value, dimensions, tags
                 NO â†’ Check enrichment worker (11-min cycle)
```

---

## âš¡ PERFORMANCE TARGETS

```
Response Time: <2s ideal (most is unavoidable LLM time)

Latency Budget (UPDATED):
  Phase 8 (LLM):         1000-5000ms  â† BOTTLENECK (70-90%)
  Phase 2.75 (Emotion):  150-250ms    â† Second bottleneck (emotion + stance + NLP cache)
  Phase 4.5 (Engines):   200-400ms    â† New strategic system (parallel, cached)
  Phase 2 (RoBERTa):     100-200ms    â† Parallel with other Phase 2 tasks
  All others:            300-500ms    â† Optimized
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL:                 1900-8800ms  â† Up from 1300-7800ms (new phases)

NEW: Strategic Cache (Phase 4.5)
  Cache hit: ~10-50ms (from PostgreSQL)
  Cache miss: ~200-400ms (run engines in parallel)
  Cache rate: ~70-80% (enrichment worker every 11min)

Storage: Non-blocking (Phase 10a-10d)
  Response returns in <2s
  All storage happens in background (asyncio.gather)
  Failures logged, don't break chat
  Parallel: 4 storage operations (Qdrant, Facts, Prefs, InfluxDB)

Concurrent: 100+ users (non-blocking storage helps!)
```

---

## ğŸ¨ PARALLEL EXECUTION WINDOWS

**Phase 2: AI Enrichment** (4 async tasks)
```
RoBERTa:  50-100ms â”€â”
Facts:    30-50ms   â”œâ”€ MAX = 50-100ms (vs 110ms serial!)
Name:     10-20ms   â”‚
CDL:      20-40ms â”€â”˜
```

**Phase 9: Storage** (4 async + non-blocking)
```
Qdrant:     20-40ms â”€â”
PostgreSQL: 10-20ms  â”œâ”€ MAX = 20-40ms (but DOESN'T BLOCK!)
Prefs:      5-10ms   â”‚
InfluxDB:   5-15ms â”€â”˜

Message returns immediately!
Storage happens async in background
```

---

## ğŸ“ WHERE DOES MY FEATURE GO?

| Need | Phase | Type |
|------|-------|------|
| Validate input | 1 | Serial, before all |
| Analyze emotion | 2 | Parallel (with others) |
| Get memories | 3 | Serial, after input |
| Build prompt | 4 | Serial, before LLM |
| Personalize | 5 | Serial, before LLM |
| Process image | 6 | Optional, conditional |
| Generate response | 7 | Serial LLM call |
| Analyze response emotion | 7.5 | Serial, after response |
| Pretty up response | 7.6 | Serial, after response |
| Check ethics | 7.7 | Serial, after response |
| Validate response | 8 | Serial, after response |
| Store data | 9 | Async, non-blocking |
| Extract learning | 10 | Serial, after storage |
| Update relationship | 11 | Serial, after learning |
| Return result | 12 | Serial, final |

---

## ğŸ› ï¸ DEBUGGING QUICK REFERENCE

**"Pipeline is slow" â†’ Check:**
```
Is it >5s? â†’ Phase 7 (LLM) - Check model/provider
Is it 1-2s? â†’ Phase 2 (RoBERTa) - Check GPU availability  
Is it <1s? â†’ Phase 9 (Storage) - Check DB latency
â†’ Look at `processing_time_ms` in result
```

**"Memory not stored" â†’ Check:**
```
1. Phase 9 logs (ğŸ’¾ STORAGE running?)
2. Datastore connectivity (Qdrant/PostgreSQL up?)
3. Run: memory_manager.store_conversation(...)
4. Query datastore directly (SELECT * FROM ...)
```

**"Wrong memories retrieved" â†’ Check:**
```
1. Phase 3 vector type (content/emotion/semantic?)
2. Recency decay (filtering recent memories?)
3. Deduplication (filtering duplicates?)
4. Direct Qdrant query with raw vectors
```

**"User facts not stored" â†’ Check:**
```
1. Phase 9b logs (ğŸ“Š PostgreSQL Facts running?)
2. NER working (spaCy entity extraction?)
3. SELECT * FROM user_fact_relationships WHERE user_id = '...'
4. No _processing_marker filtering (that's enrichment metadata)
```

---

## ğŸ“š KEY DATABASES

```
Qdrant (Vector Memory)
  â”œâ”€ Collection: whisperengine_memory_{bot_name}
  â”œâ”€ Per memory: 3 vectors (384D) + 12+ metadata
  â””â”€ Query: Semantic search + quality scoring

PostgreSQL (Knowledge Graph)
  â”œâ”€ user_fact_relationships (facts)
  â”œâ”€ fact_entities (entity definitions)
  â”œâ”€ universal_users (user identity + preferences JSONB)
  â”œâ”€ relationship_metrics (trust/affection/attunement)
  â””â”€ character_* (50+ character CDL tables)

InfluxDB (Time-Series)
  â”œâ”€ User emotion evolution (hourly)
  â”œâ”€ Bot emotion evolution (hourly)
  â”œâ”€ Confidence trends
  â”œâ”€ Conversation quality metrics
  â””â”€ Retention: 30 days (auto-purged)
```

---

## ğŸš¨ CRITICAL CONSTRAINTS

**Qdrant Schema FROZEN** ğŸ”’
- 384D vectors (CANNOT CHANGE!)
- Named vectors: content, emotion, semantic (FIXED)
- Payload fields: user_id, memory_type, content, timestamp (LOCKED)
- ADDITIVE ONLY (add new fields, never remove)

**Message Order STRICT** ğŸ“‹
- Security (Phase 1) BEFORE processing
- LLM (Phase 7) needs all previous context
- Validation (Phase 8) BEFORE storage
- Cannot reorder without careful analysis

**Storage NON-BLOCKING** âš¡
- return_exceptions=True (failures logged, not fatal)
- Trade-off: Speed vs 100% reliability
- Errors in logs, not in response

**Character Data DYNAMIC** ğŸ­
- All from PostgreSQL (no hardcoding!)
- Via DISCORD_BOT_NAME environment variable
- Run once at startup, not per message

---

## ğŸ“Š SUMMARIZATION SYSTEMS COMPARISON

| System | Speed | Quality | Storage | When | Use For |
|--------|-------|---------|---------|------|---------|
| Real-Time | 5-20ms | Low | None | Phase 3 | Token budget |
| Background | 2-5s | High | PostgreSQL | 24h async | Storage |
| Advanced | 500ms-1s | Medium | Cache 1h | Opt real-time | Balanced |

**Don't mix them up!**
- Need fast? â†’ Real-Time (no LLM)
- Need quality? â†’ Background (high-quality LLM)
- Need balance? â†’ Advanced (medium effort)

---

## ğŸ“ LEARNING PATH (Time Estimates)

```
â±ï¸  5 min:   Read "3 Golden Rules" + this quick ref
â±ï¸  15 min:  Read MESSAGE_PIPELINE_EXECUTIVE_SUMMARY.md
â±ï¸  30 min:  Read MESSAGE_PIPELINE_AND_SUMMARIES_REVIEW.md (overview)
â±ï¸  15 min:  Look at MESSAGE_PIPELINE_VISUAL_FLOWS.md diagrams
â±ï¸  30 min:  Trace src/core/message_processor.py code
â±ï¸  30 min:  Run test: test_memory_intelligence_convergence_complete_validation.py
â±ï¸  â”€â”€â”€â”€â”€â”€
      2h:    Complete understanding
```

---

## ğŸ“ KEY CODE LOCATIONS

```
Main Pipeline:        src/core/message_processor.py (8,000+ lines)
RoBERTa Emotion:      src/intelligence/enhanced_vector_emotion_analyzer.py
Qdrant Memory:        src/memory/vector_memory_system.py (5,363 lines)
CDL Character:        src/prompts/cdl_ai_integration.py (3,458 lines)
Real-Time Summaries:  src/utils/helpers.py (~220 lines)
Background Summaries: src/enrichment/summarization_engine.py
Advanced Summaries:   src/memory/conversation_summarizer.py
Tests:                tests/automated/test_memory_intelligence_convergence_*
```

---

## âœ… CHECKLIST: READY TO USE THIS?

- [ ] Understand 3 golden rules (you should now)
- [ ] Know which phase your feature goes in (use table above)
- [ ] Know which datastore to use (use decision tree)
- [ ] Know how to debug if something breaks (use quick ref)
- [ ] Know where to look in code (use code locations)
- [ ] Ready to read full documents if needed (they exist!)

---

## ğŸ¯ NEXT STEPS

**To Add a Feature:**
1. âœ… Use "Where does my feature go?" table
2. âœ… Read that phase in full documents
3. âœ… Find code in src/core/message_processor.py
4. âœ… Implement + test with test_*_validation.py

**To Debug:**
1. âœ… Use "Debugging Quick Reference" above
2. âœ… Check logs for phase timing
3. âœ… Query datastore directly
4. âœ… Run isolated test

**To Understand More:**
1. âœ… Read MESSAGE_PIPELINE_EXECUTIVE_SUMMARY.md
2. âœ… Read MESSAGE_PIPELINE_AND_SUMMARIES_REVIEW.md
3. âœ… Study MESSAGE_PIPELINE_VISUAL_FLOWS.md
4. âœ… Use MESSAGE_PIPELINE_COMPLETE_INDEX.md for navigation

---

**Bookmark this page! Print it! Reference it when:**
- Adding new features
- Debugging issues
- Onboarding team members
- Making architecture decisions

**WhisperEngine: 18 months of evolution. 10+ live characters. Millions of messages. This is production-grade AI architecture.** âœ…

---

*Created: November 5, 2025 | Status: Ready to Use | Version: 1.0*
