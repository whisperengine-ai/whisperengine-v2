# Design Document Gap Analysis & User Preferences Integration

**Date**: October 4, 2025  
**Status**: Gap analysis complete, enhancement plan defined

## üéØ Executive Summary

The original **SEMANTIC_KNOWLEDGE_GRAPH_DESIGN.md** was a comprehensive architecture plan with 4 phases. We successfully implemented **Phase 1-4** for factual knowledge (food preferences, hobbies, etc.), but several features from the original design remain unimplemented:

### ‚úÖ Implemented from Original Design
- Phase 1: PostgreSQL schema (fact_entities, user_fact_relationships, entity_relationships, character_interactions)
- Phase 2: SemanticKnowledgeRouter with query intent analysis
- Phase 3: Knowledge extraction pipeline in MessageProcessor
- Phase 4: Character integration via CDLAIPromptIntegration
- Auto-user-creation in universal_users table
- Character-aware fact retrieval

### ‚ùå NOT Implemented from Original Design
1. **InfluxDB temporal analytics** - Confidence evolution tracking, preference trends
2. **User preferences in PostgreSQL** - Preferred names, general preferences
3. **Enhanced users table** - Original design called for richer user metadata
4. **Relationship discovery queries** - 2-hop graph traversal queries
5. **Full-text entity search** - Search vector functionality
6. **Entity auto-discovery** - Trigram similarity matching for similar entities

## üìä Current vs Designed Architecture

### Original Design: Multi-Modal Data Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    WhisperEngine Data Ecosystem                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   POSTGRESQL    ‚îÇ  VECTOR SPACE   ‚îÇ  TIME ANALYTICS ‚îÇ   CDL SYSTEM    ‚îÇ
‚îÇ  (Structured)   ‚îÇ   (Semantic)    ‚îÇ   (Evolution)   ‚îÇ  (Character)    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ User Identity ‚îÇ ‚Ä¢ Qdrant DB     ‚îÇ ‚Ä¢ InfluxDB      ‚îÇ ‚Ä¢ JSON Files    ‚îÇ
‚îÇ ‚Ä¢ Facts/Relations‚îÇ ‚Ä¢ Conversation ‚îÇ ‚Ä¢ Confidence    ‚îÇ ‚Ä¢ Personality   ‚îÇ
‚îÇ ‚Ä¢ Graph queries ‚îÇ   similarity    ‚îÇ   evolution     ‚îÇ ‚Ä¢ Voice Style   ‚îÇ
‚îÇ ‚Ä¢ Recommendations‚îÇ ‚Ä¢ Emotion flow ‚îÇ ‚Ä¢ Interaction   ‚îÇ ‚Ä¢ AI Identity   ‚îÇ
‚îÇ ‚Ä¢ Analytics     ‚îÇ ‚Ä¢ Context       ‚îÇ   frequency     ‚îÇ ‚Ä¢ Background    ‚îÇ
‚îÇ ‚Ä¢ Transactions  ‚îÇ   switching     ‚îÇ ‚Ä¢ Memory decay  ‚îÇ ‚Ä¢ Conversation  ‚îÇ
‚îÇ ‚Ä¢ Full-text     ‚îÇ ‚Ä¢ Character     ‚îÇ ‚Ä¢ Trends        ‚îÇ   patterns      ‚îÇ
‚îÇ   search        ‚îÇ   matching      ‚îÇ ‚Ä¢ Analytics     ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Current Implementation: Simplified Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               WhisperEngine ACTUAL Data Ecosystem                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   POSTGRESQL    ‚îÇ  VECTOR SPACE   ‚îÇ  TIME ANALYTICS ‚îÇ   CDL SYSTEM    ‚îÇ
‚îÇ  (Structured)   ‚îÇ   (Semantic)    ‚îÇ   (Evolution)   ‚îÇ  (Character)    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ User Identity ‚îÇ ‚Ä¢ Qdrant DB     ‚îÇ  ‚ùå NO INFLUX  ‚îÇ ‚Ä¢ JSON Files    ‚îÇ
‚îÇ   (auto-create) ‚îÇ ‚Ä¢ Conversation ‚îÇ                 ‚îÇ ‚Ä¢ Personality   ‚îÇ
‚îÇ ‚Ä¢ Fact entities ‚îÇ   similarity    ‚îÇ                 ‚îÇ ‚Ä¢ Voice Style   ‚îÇ
‚îÇ ‚Ä¢ User-fact     ‚îÇ ‚Ä¢ Emotion flow ‚îÇ                 ‚îÇ ‚Ä¢ AI Identity   ‚îÇ
‚îÇ   relationships ‚îÇ ‚Ä¢ Context       ‚îÇ                 ‚îÇ ‚Ä¢ Background    ‚îÇ
‚îÇ ‚Ä¢ Character     ‚îÇ   switching     ‚îÇ                 ‚îÇ ‚Ä¢ Conversation  ‚îÇ
‚îÇ   interactions  ‚îÇ ‚Ä¢ USER PREFS   ‚îÇ                 ‚îÇ   patterns      ‚îÇ
‚îÇ ‚ùå NO full-text‚îÇ ‚Ä¢ Character     ‚îÇ                 ‚îÇ                 ‚îÇ
‚îÇ ‚ùå NO analytics‚îÇ   matching      ‚îÇ                 ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Difference**: User preferences (including preferred names) are currently stored in **Qdrant vector memory**, NOT PostgreSQL as originally designed.

## üö® User Preferences: Current State

### Current Implementation (Vector Memory)

**Location**: `src/utils/user_preferences.py`

**How It Works**:
1. User says: "My name is Mark" or "Call me Mark" or "I prefer to be called Mark"
2. Stored in Qdrant vector memory as part of conversation
3. Retrieved via semantic search when needed
4. Pattern matching extracts name from text

**Problems with Current Approach**:
- ‚ùå Requires semantic search every time (slow)
- ‚ùå Name conflicts possible (multiple names over time)
- ‚ùå No structured preference storage
- ‚ùå Not queryable via SQL
- ‚ùå Not integrated with PostgreSQL facts system

### Original Design (PostgreSQL)

**Intended Schema** (from design doc):

```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    discord_id BIGINT UNIQUE,
    username TEXT,
    preferred_name TEXT,  -- ‚Üê This was supposed to store preferred names!
    user_metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

**Actual Schema** (what exists now):

```sql
CREATE TABLE universal_users (
    universal_id VARCHAR(255) PRIMARY KEY,  -- Discord ID
    primary_username VARCHAR(255) NOT NULL,
    display_name VARCHAR(255),
    email VARCHAR(255),
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    last_active TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    preferences TEXT DEFAULT '{}',  -- ‚Üê JSONB text, not structured!
    privacy_settings TEXT DEFAULT '{}'
);
```

**Gap**: The `preferences` column exists but is **not being used** for preferred names or any user preferences!

## üí° Integration Plan: User Preferences in PostgreSQL

### Phase 5: User Preferences Integration

#### Goal
Store user preferences (preferred names, general preferences) in PostgreSQL for:
- Fast, deterministic retrieval (no semantic search needed)
- Structured preference management
- Integration with knowledge graph
- SQL queryability and analytics

#### Implementation Strategy

**1. Enhance Knowledge Extraction** (MessageProcessor)

Add preference detection alongside fact detection:

```python
# In src/core/message_processor.py - _extract_and_store_knowledge()

async def _extract_and_store_user_preferences(self, message_context: MessageContext) -> bool:
    """Extract and store user preferences (name, general preferences)"""
    
    content = message_context.content
    user_id = message_context.user_id
    
    # Detect preferred name
    name_patterns = [
        r"(?:my name is|call me|I am|I'm|i prefer to be called)\s+([A-Z][a-z]+)",
        r"just call me\s+([A-Z][a-z]+)",
        r"you can call me\s+([A-Z][a-z]+)"
    ]
    
    for pattern in name_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            preferred_name = match.group(1)
            
            # Store in PostgreSQL
            if hasattr(self.bot_core, 'knowledge_router'):
                success = await self.bot_core.knowledge_router.store_user_preference(
                    user_id=user_id,
                    preference_type='preferred_name',
                    preference_value=preferred_name,
                    confidence=0.9
                )
                if success:
                    logger.info(f"‚úÖ PREFERENCE: Stored preferred name '{preferred_name}' for user {user_id}")
                    return True
    
    return False
```

**2. Add Method to SemanticKnowledgeRouter**

```python
# In src/knowledge/semantic_router.py

async def store_user_preference(
    self,
    user_id: str,
    preference_type: str,  # 'preferred_name', 'timezone', 'language', etc.
    preference_value: str,
    confidence: float = 1.0
) -> bool:
    """Store user preference in PostgreSQL"""
    try:
        async with self.postgres.acquire() as conn:
            # Update universal_users.preferences JSONB
            await conn.execute("""
                UPDATE universal_users
                SET preferences = preferences::jsonb || 
                    jsonb_build_object(
                        $2::text, 
                        jsonb_build_object(
                            'value', $3::text,
                            'confidence', $4::float,
                            'updated_at', NOW()::text
                        )
                    )
                WHERE universal_id = $1
            """, user_id, preference_type, preference_value, confidence)
            
            logger.info(f"‚úÖ Stored preference {preference_type}={preference_value} for user {user_id}")
            return True
    except Exception as e:
        logger.error(f"‚ùå Failed to store preference: {e}")
        return False

async def get_user_preference(
    self,
    user_id: str,
    preference_type: str
) -> Optional[Dict[str, Any]]:
    """Retrieve user preference from PostgreSQL"""
    try:
        async with self.postgres.acquire() as conn:
            result = await conn.fetchval("""
                SELECT preferences::jsonb -> $2
                FROM universal_users
                WHERE universal_id = $1
            """, user_id, preference_type)
            
            if result:
                import json
                return json.loads(result)
            return None
    except Exception as e:
        logger.error(f"‚ùå Failed to retrieve preference: {e}")
        return None
```

**3. Update CDL Integration**

Replace vector memory lookup with PostgreSQL:

```python
# In src/prompts/cdl_ai_integration.py - create_unified_character_prompt()

# OLD: Vector memory search
# preferred_name = await get_user_preferred_name(user_id, self.memory_manager, user_name)

# NEW: PostgreSQL preference lookup
preferred_name = None
if self.knowledge_router:
    pref_data = await self.knowledge_router.get_user_preference(
        user_id=user_id,
        preference_type='preferred_name'
    )
    if pref_data:
        preferred_name = pref_data.get('value')

display_name = preferred_name or user_name or "User"
```

#### Benefits

1. **Performance**: Direct PostgreSQL query (< 1ms) vs semantic search (10-50ms)
2. **Deterministic**: Always returns the correct, most recent preference
3. **Structured**: JSONB allows complex preference objects
4. **Integrated**: Works alongside knowledge graph facts
5. **Queryable**: Can run SQL analytics on user preferences
6. **Confidence tracking**: Track how certain we are about each preference
7. **Temporal**: Automatic `updated_at` timestamps

#### Example Preference Storage

```json
{
  "preferred_name": {
    "value": "Mark",
    "confidence": 0.9,
    "updated_at": "2025-10-04T14:30:00"
  },
  "timezone": {
    "value": "America/Los_Angeles",
    "confidence": 1.0,
    "updated_at": "2025-10-04T10:00:00"
  },
  "language": {
    "value": "en",
    "confidence": 1.0,
    "updated_at": "2025-10-04T10:00:00"
  },
  "communication_style": {
    "value": "casual",
    "confidence": 0.7,
    "updated_at": "2025-10-04T12:00:00"
  }
}
```

## üìã Other Design Document Features Not Implemented

### 1. InfluxDB Temporal Analytics

**Original Design**: Track confidence evolution, interaction frequency, preference trends

**Current Reality**: No temporal tracking - facts have timestamps but no evolution analysis

**Future Enhancement**:
```python
# Would track things like:
- "User's enthusiasm for pizza grew from 0.7 to 0.9 confidence over 2 weeks"
- "User mentions hiking 3x per week on average"
- "Coffee preference declining (0.9 ‚Üí 0.6 over past month)"
```

**Priority**: LOW - Nice to have but not critical for core functionality

### 2. Relationship Discovery (2-hop Graph Queries)

**Original Design**: Find related entities via graph traversal

Example query from design doc:
```sql
-- "What foods are similar to pizza?"
WITH user_foods AS (...),
related_foods AS (...)
SELECT entity_name, weight, relationship_type
FROM related_foods
ORDER BY weight * source_confidence DESC;
```

**Current Reality**: Entity relationships table exists but not populated. Similar entity discovery code in router but untested.

**Future Enhancement**: Would enable queries like:
- "What hobbies are similar to hiking?" ‚Üí camping, rock climbing, trail running
- "What foods pair well with pizza?" ‚Üí beer, salad, wine

**Priority**: MEDIUM - Useful for recommendations and discovery

### 3. Full-Text Entity Search

**Original Design**: Search entities using PostgreSQL full-text search

**Current Reality**: Schema has `search_vector` column (auto-generated tsvector) but no search queries using it

**Future Enhancement**:
```sql
SELECT entity_name, category, entity_type,
       ts_rank(search_vector, plainto_tsquery('english', $1)) as relevance
FROM fact_entities
WHERE search_vector @@ plainto_tsquery('english', $1)
ORDER BY relevance DESC;
```

**Priority**: LOW - Pattern matching works adequately for now

### 4. Enhanced User Metadata

**Original Design**: Rich user profiles with metadata

**Current Reality**: Minimal user data (just Discord ID and timestamps)

**Gap**: No user profile data, demographics, or extended attributes

**Priority**: MEDIUM - Would improve personalization

## üéØ Recommended Implementation Priority

### Phase 5 (IMMEDIATE): User Preferences Integration
**Why**: Critical usability feature, performance improvement, completes knowledge graph
- Preferred names ‚Üí PostgreSQL
- General preferences ‚Üí PostgreSQL
- Fast, deterministic retrieval
- Integration with existing knowledge router

**Effort**: 2-4 hours  
**Impact**: HIGH - Immediate user experience improvement

### Phase 6 (SOON): Entity Relationship Discovery
**Why**: Enables recommendations and natural discovery
- Populate entity_relationships via trigram matching
- Implement 2-hop graph queries
- "What's similar to X?" queries

**Effort**: 4-6 hours  
**Impact**: MEDIUM - Enhances conversation intelligence

### Phase 7 (FUTURE): Temporal Analytics with InfluxDB
**Why**: Track preference evolution and interaction trends
- Confidence evolution over time
- Interaction frequency analysis
- Preference trend detection

**Effort**: 8-12 hours  
**Impact**: MEDIUM - Advanced analytics, not core functionality

### Phase 8 (FUTURE): Full-Text Search & Enhanced Profiles
**Why**: Power user features and advanced discovery
- Full-text entity search
- Rich user profiles
- Advanced analytics

**Effort**: 6-10 hours  
**Impact**: LOW - Nice to have for scale

## üîë Key Takeaways

1. **Design Document Status**: ~50% implemented
   - ‚úÖ Core knowledge graph (Phases 1-4)
   - ‚ùå User preferences, temporal analytics, advanced queries

2. **User Preferences Current State**:
   - Stored in **Qdrant vector memory** (slow, unreliable)
   - Should be in **PostgreSQL** (fast, deterministic)
   - `universal_users.preferences` column exists but unused!

3. **Easy Win**: Phase 5 (User Preferences)
   - 2-4 hours implementation
   - Massive UX improvement
   - Completes knowledge graph foundation
   - Uses existing infrastructure

4. **Future Enhancements**: Phases 6-8
   - Not blocking production
   - Can be added iteratively
   - Original design was ambitious but achievable

## üìù Next Steps

**Immediate** (Phase 5):
1. Implement `store_user_preference()` in SemanticKnowledgeRouter
2. Add preference detection to MessageProcessor
3. Update CDL integration to use PostgreSQL preferences
4. Test with "My name is Mark" patterns
5. Validate performance improvement

**Soon** (Phase 6):
1. Implement relationship discovery queries
2. Populate entity_relationships via similarity
3. Add "similar to" recommendation engine

**Future** (Phases 7-8):
1. Evaluate InfluxDB for temporal analytics
2. Consider full-text search if needed at scale
3. Enhance user profiles if personalization demands grow

---

**Summary**: The original design was excellent and comprehensive. We successfully implemented the core knowledge graph (Phases 1-4), but several important features remain - most critically, **user preferences should move from vector memory to PostgreSQL** for better performance and reliability.
