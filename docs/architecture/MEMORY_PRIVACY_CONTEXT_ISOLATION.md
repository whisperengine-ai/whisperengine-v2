# Memory Privacy & Context Isolation

**Status**: ðŸ“‹ DOCUMENTED - Design Decision Pending  
**Date**: October 18, 2025  
**Issue Type**: Privacy/UX Tradeoff  
**Priority**: Medium (Mixed User Feedback)

---

## ðŸŽ¯ Executive Summary

WhisperEngine currently retrieves ALL user memories regardless of conversation context (DM vs. public channel). This creates a **fundamental tradeoff** between relationship continuity and privacy protection. User feedback is **mixed** - some users appreciate the continuity, others have privacy concerns.

**Current Behavior**: When a user talks to a bot in a DM, then later talks to the same bot in a public Discord channel, the bot has access to ALL previous memories including private DM conversations. The bot may mention personal topics from DMs when responding publicly.

**User Feedback**:
- âœ… **Positive**: "It's been good for continuity" - users appreciate bots remembering context across platforms
- âš ï¸ **Concerns**: Some users have expressed discomfort with personal topics being mentioned in public contexts
- ðŸ’­ **Nuanced**: Different users have different expectations about memory boundaries

---

## ðŸ” Technical Analysis

### Current Architecture

**Collection-Based Bot Isolation**:
- Each character bot has its own dedicated Qdrant collection
- Elena: `whisperengine_memory_elena`
- Marcus: `whisperengine_memory_marcus`
- Jake: `whisperengine_memory_jake`
- Collections provide complete memory isolation between different AI characters

**Memory Storage** (Working Correctly):
```python
# src/memory/vector_memory_system.py - Lines 5785-5824
# Security level IS tracked and stored properly

if message.guild is None:
    security_level = ContextSecurity.PRIVATE_DM
else:
    is_private_channel = self._is_private_channel(message.channel)
    if is_private_channel:
        security_level = ContextSecurity.PRIVATE_CHANNEL
    else:
        security_level = ContextSecurity.PUBLIC_CHANNEL

# Metadata stored with each memory:
# - channel_id
# - guild_id (if applicable)
# - security_level (PRIVATE_DM, PRIVATE_CHANNEL, PUBLIC_CHANNEL)
# - platform ("discord")
# - user_id (unique per user)
# 
# NOTE: No character_name or bot_name in metadata
# Facts are NOT scoped to which character learned them
# Collection isolation = bot-level, not fact-level
```

**âš ï¸ IMPORTANT: Cross-Character Fact Sharing**:

Within a single bot's collection, **facts are shared across all interactions**. This means:

1. **No Character Attribution**: Facts don't track which "character persona" learned them
2. **User-Scoped Only**: Facts are filtered by `user_id` only, not by context of discovery
3. **Implication**: If Elena learns "user likes Python" in one conversation context, that fact is available in ALL contexts within Elena's memory

This is by design for simplicity, but creates interesting scenarios:
- âœ… **Good**: User doesn't need to re-teach the same facts to the same bot
- âš ï¸ **Consideration**: Facts learned in DM available in public (the problem we're solving)
- ðŸ¤” **Future**: Could track `learned_by_character` in metadata if multi-persona bots emerge

**Current Fact Storage** (No Character Tracking):
```python
# src/memory/vector_memory_system.py - Lines 5428-5455
async def store_fact(
    self,
    user_id: str,
    fact: str,
    context: str,
    confidence: float = 1.0,
    metadata: Optional[Dict[str, Any]] = None
) -> bool:
    fact_memory = VectorMemory(
        id=str(uuid4()),
        user_id=user_id,  # ONLY user scoping
        memory_type=MemoryType.FACT,
        content=fact,
        metadata={
            "context": context,
            **(metadata or {})
            # No character_name or bot_name field
        }
    )
    # Stored in bot's collection (e.g., whisperengine_memory_elena)
    # Facts accessible across all conversations within this bot
```

**Memory Retrieval** (No Filtering):
```python
# src/memory/vector_memory_system.py - Lines 4172-4250, 4686-4750
# retrieve_relevant_memories() methods

async def retrieve_relevant_memories(
    self,
    user_id: str,      # ONLY filter by user_id
    query: str,
    limit: int = 25,
    emotion_data: Optional[Dict[str, Any]] = None
    # NO security_context parameter
    # NO channel_id filtering
) -> List[Dict[str, Any]]:
    # All memories retrieved regardless of conversation context
```

**Key Finding**: Infrastructure exists to support filtering (security_level tracked), but filtering is intentionally not implemented in retrieval methods.

### Cross-Character Fact Sharing Implications

**Current Behavior**: Facts are scoped by `user_id` only, NOT by character or conversation context.

**What This Means**:
```
User talks to Elena in DM â†’ Learns "user has a cat named Whiskers"
User talks to Elena in public channel â†’ Elena knows about Whiskers

User talks to Elena â†’ Learns "user lives in Seattle"  
User talks to Marcus â†’ Marcus does NOT know about Seattle
(Different Qdrant collections = complete bot isolation)
```

**Privacy Interaction with Hybrid Filtering**:

The hybrid filtering solution addresses **channel context**, but facts are still shared within a bot's memory:

| Scenario | Current Behavior | With Hybrid Filtering |
|----------|------------------|----------------------|
| DM fact â†’ Public channel (same bot) | âœ… Fact accessible | âŒ Fact filtered (PRIVATE_DM) |
| DM fact â†’ DM (same bot) | âœ… Fact accessible | âœ… Fact accessible |
| Public fact â†’ Public channel (same bot) | âœ… Fact accessible | âœ… Fact accessible |
| DM fact â†’ Different bot | âŒ Not accessible (collection isolation) | âŒ Not accessible (collection isolation) |

**Design Decision Rationale**:
- âœ… **No character tracking needed**: Collection-based isolation is sufficient
- âœ… **Simpler architecture**: User-scoped facts, no character attribution complexity
- âœ… **Consistent UX**: User teaches facts once per bot, not per conversation context
- âš ï¸ **Privacy handled by channel filtering**: Hybrid filtering solves the actual privacy problem

**Future Consideration**: If WhisperEngine adds multi-persona bots (e.g., Elena in "teacher mode" vs. "friend mode"), could add `learned_by_character` metadata field. This would be an **additive change** (Qdrant schema compatible).

### Qdrant Schema Status

**ðŸš¨ SCHEMA CONSTRAINT**: WhisperEngine has production users - schema changes must be **ADDITIVE ONLY**.

**Current Schema** (Frozen):
- âœ… Named vectors: content (384D), emotion (384D), semantic (384D)
- âœ… Required payload fields: user_id, memory_type, content, timestamp
- âœ… Metadata fields: channel_id, guild_id, security_level, platform

**Potential Changes** (All additive-compatible):
- âœ… Can add new optional payload fields
- âœ… Can add filtering logic without schema changes
- âœ… Can backfill security_level for old memories via metadata migration
- âŒ Cannot change vector dimensions
- âŒ Cannot rename existing fields

---

## ðŸ“Š User Feedback Analysis

### Positive Continuity Experiences

**What Users Like**:
- Bots remember ongoing conversations regardless of platform
- No need to "re-introduce" yourself when switching contexts
- Natural relationship progression across DMs and public channels
- Feels more human-like (humans remember all previous conversations)

**Example Scenarios**:
- User asks bot a complex question in DM, gets detailed answer
- Later mentions the topic briefly in public channel
- Bot understands context immediately without re-explanation
- User appreciates not having to repeat themselves

### Privacy Concerns

**What Users Worry About**:
- Personal topics from DMs being mentioned in public spaces
- Potential for embarrassment or discomfort
- Assumption that DM = private context isolation
- Discord social norms: DMs are private, channels are public

**Example Problem Scenarios**:
- User discusses personal mental health topic in DM with bot
- Later says "hi" to bot in public guild channel
- Bot responds: "Hi! Hope you're feeling better about [personal topic]"
- Other Discord members see the public response

### Mixed Feedback Interpretation

**Why Feedback is Mixed**:
1. **Different User Expectations**: Some users expect full continuity, others expect context isolation
2. **Use Case Variability**: Educational vs. emotional support vs. casual conversation
3. **Discord Norms**: Platform has both public and private spaces, but WhisperEngine is cross-platform
4. **Character Archetypes**: Fantasy characters vs. realistic AI assistants have different expectations

**User Sentiment Breakdown** (Qualitative):
- ~50% appreciate full continuity
- ~30% have privacy concerns
- ~20% haven't thought about it / no strong opinion

---

## ðŸŽ¯ Design Options

### Option 1: Hybrid Filtering - Facts Isolated, Conversations Shared (RECOMMENDED â­)

**Core Insight**: The privacy problem is mainly about **FACTS** (user details, preferences, personal information), not **CONVERSATION FLOW**. 

**Filtering Strategy**:
```python
# Different rules for different memory types

# FACTS & PREFERENCES: Strict channel isolation
if memory_type in [MemoryType.FACT, MemoryType.PREFERENCE]:
    # DM facts stay in DM ONLY
    if security_context == ContextSecurity.PRIVATE_DM:
        filter_condition = security_level == "PRIVATE_DM"
    
    # Private channel facts stay in that channel ONLY
    elif security_context == ContextSecurity.PRIVATE_CHANNEL:
        filter_condition = (security_level == "PRIVATE_CHANNEL" 
                           AND channel_id == current_channel_id)
    
    # Public channels share ALL public channel facts (any guild)
    elif security_context == ContextSecurity.PUBLIC_CHANNEL:
        filter_condition = security_level == "PUBLIC_CHANNEL"

# CONVERSATIONS: Full continuity (current behavior)
if memory_type == MemoryType.CONVERSATION:
    # No filtering - maintains relationship continuity
    # Conversation flow is OK to reference across contexts
```

**Privacy Rules by Memory Type**:

| Memory Type | DM | Private Channel | Public Channel |
|------------|-----|-----------------|----------------|
| **Facts/Preferences** | DM only | That channel only | All public channels |
| **Conversations** | All contexts | All contexts | All contexts |
| **Emotions** | All contexts | All contexts | All contexts |

**Example Scenarios**:

1. **Sensitive Fact Protection**:
   - User in DM: "I have a $1M estate I'm hiding from my wife"
   - Bot stores as FACT with security_level=PRIVATE_DM
   - User in public channel: "Hey bot!"
   - Bot response: Does NOT mention estate (fact filtered out)
   - âœ… Privacy protected

2. **Conversation Continuity Maintained**:
   - User in DM: "Can you explain quantum entanglement?"
   - Bot gives detailed explanation
   - User in public channel: "Thanks for that quantum explanation earlier"
   - Bot: "You're welcome! The spooky action at a distance concept is fascinating, right?"
   - âœ… Natural conversation flow preserved

3. **Public Facts Share Across Guilds**:
   - User in Guild A public channel: "I'm learning Python"
   - Stored as FACT with security_level=PUBLIC_CHANNEL
   - User in Guild B public channel: "Remember I'm learning Python?"
   - Bot: "Yes! How's your Python learning going?"
   - âœ… Legitimate continuity across public contexts

**Pros**:
- âœ… **Solves privacy problem**: Sensitive facts stay isolated
- âœ… **Maintains conversation quality**: Natural dialogue flow preserved
- âœ… **Best of both worlds**: Security + continuity
- âœ… **Intuitive behavior**: Facts are private, conversations are contextual
- âœ… **Aligns with user mental model**: "I told you a secret in DM" vs. "we were talking about quantum physics"
- âœ… **Minimal impact on UX**: Bots don't seem "forgetful" about conversations

**Cons**:
- âš ï¸ **Implementation complexity**: Two different filtering strategies
- âš ï¸ **Edge cases**: What about facts derived from conversations?
- âš ï¸ **User confusion**: Might be unclear why bot remembers some things but not others
- âš ï¸ **Knowledge graph implications**: Entity relationships might span contexts

**Implementation Sketch**:
```python
async def retrieve_relevant_memories(
    self,
    user_id: str,
    query: str,
    limit: int = 25,
    emotion_data: Optional[Dict[str, Any]] = None,
    security_context: Optional[ContextSecurity] = None,
    channel_id: Optional[str] = None
) -> List[Dict[str, Any]]:
    
    # Retrieve conversations (no filtering)
    conversations = await self._retrieve_by_type(
        user_id=user_id,
        query=query,
        memory_types=[MemoryType.CONVERSATION],
        limit=limit // 2  # Split limit
    )
    
    # Retrieve facts (WITH filtering)
    facts = await self._retrieve_facts_filtered(
        user_id=user_id,
        query=query,
        security_context=security_context,
        channel_id=channel_id,
        limit=limit // 2
    )
    
    # Combine and re-rank
    return merge_and_rank(conversations, facts)
```

---

### Option 2: Full Context-Aware Filtering (All Memory Types)

**Implementation**:
```python
# Apply same filtering to ALL memory types
if security_context == ContextSecurity.PUBLIC_CHANNEL:
    must_conditions.append(
        models.FieldCondition(
            key="security_level",
            match=models.MatchValue(value="PUBLIC_CHANNEL")
        )
    )
```

**Rules**:
- **DM Conversations**: Retrieve ALL memories (PRIVATE_DM + PRIVATE_CHANNEL + PUBLIC_CHANNEL)
- **Private Channel**: Retrieve channel-specific + public memories
- **Public Channel**: Retrieve ONLY PUBLIC_CHANNEL memories

**Pros**:
- âœ… Maximum privacy protection (everything isolated)
- âœ… Simple, uniform rule across all memory types
- âœ… No edge cases or ambiguity

**Cons**:
- âŒ Bots seem "forgetful" in public channels
- âŒ Breaks conversation continuity
- âŒ Users frustrated by context-switching
- âŒ Character relationship feels fragmented

### Option 3: User-Controlled Settings

**Implementation**:
Add `/whisper settings memory-mode` Discord command with options:
- **Full Continuity** (current): All memories available in all contexts
- **Context-Aware** (recommended): Public channels filtered, DMs unfiltered
- **Channel-Isolated**: Strict isolation, each channel gets own memory pool

**Pros**:
- âœ… User decides their own privacy/continuity balance
- âœ… Accommodates different user preferences
- âœ… No one-size-fits-all compromise
- âœ… Empowers users with control

**Cons**:
- âŒ Complex to implement (per-user settings storage)
- âŒ User education burden (most won't understand the tradeoff)
- âŒ Potential confusion ("why does bot remember X but not Y?")
- âŒ Settings fragmentation across multiple bots
- âŒ Default setting still needs to be chosen

### Option 4: Smart Redaction

**Implementation**:
Keep full memory retrieval but use LLM to detect and redact sensitive details in public contexts:
```python
# Pseudo-code
if security_context == ContextSecurity.PUBLIC_CHANNEL:
    memories = await retrieve_all_memories(user_id, query)
    redacted_memories = await llm_redact_sensitive_details(
        memories=memories,
        context="public channel response"
    )
    return redacted_memories
```

**Pros**:
- âœ… Maintains relationship continuity
- âœ… Protects sensitive details
- âœ… More nuanced than binary filtering
- âœ… Users don't lose context completely

**Cons**:
- âŒ Complex to implement reliably
- âŒ LLM may still leak information subtly
- âŒ Performance overhead (additional LLM calls)
- âŒ Hard to validate effectiveness
- âŒ Unclear boundary: what is "sensitive"?
- âŒ Still risks privacy violations

---

## ðŸ”§ Implementation Considerations

### Hybrid Filtering Implementation Details

**Architecture Note**: Facts are **user-scoped only** (no character attribution within a bot's memory). Filtering is by `channel context`, not by `who learned the fact`. This keeps implementation simple while solving the privacy problem.

**Phase 1: Fact Retrieval Methods** (Primary Target)

```python
# src/memory/vector_memory_system.py - Lines 5456+

async def retrieve_facts(
    self,
    user_id: str,
    query: str,
    limit: int = 10,
    security_context: Optional[ContextSecurity] = None,  # NEW
    channel_id: Optional[str] = None  # NEW
) -> List[Dict[str, Any]]:
    """Retrieve facts with channel-based privacy filtering."""
    
    # Build base conditions
    must_conditions = [
        models.FieldCondition(
            key="user_id",
            match=models.MatchValue(value=user_id)
        ),
        models.FieldCondition(
            key="memory_type",
            match=models.MatchValue(value=MemoryType.FACT.value)
        )
    ]
    
    # Apply privacy filtering
    if security_context == ContextSecurity.PRIVATE_DM:
        # DM facts stay in DM only
        must_conditions.append(
            models.FieldCondition(
                key="security_level",
                match=models.MatchValue(value="PRIVATE_DM")
            )
        )
    
    elif security_context == ContextSecurity.PRIVATE_CHANNEL:
        # Private channel facts stay in that channel only
        must_conditions.append(
            models.FieldCondition(
                key="security_level",
                match=models.MatchValue(value="PRIVATE_CHANNEL")
            )
        )
        if channel_id:
            must_conditions.append(
                models.FieldCondition(
                    key="channel_id",
                    match=models.MatchValue(value=channel_id)
                )
            )
    
    elif security_context == ContextSecurity.PUBLIC_CHANNEL:
        # Public channel facts are shared across all public channels
        must_conditions.append(
            models.FieldCondition(
                key="security_level",
                match=models.MatchValue(value="PUBLIC_CHANNEL")
            )
        )
    
    # If no security_context provided, retrieve all (backward compatibility)
    
    # Execute search with filters
    results = await self.vector_store.search_memories(
        query=query,
        user_id=user_id,
        memory_types=[MemoryType.FACT.value],
        limit=limit,
        additional_filters=must_conditions
    )
    
    return results
```

**Phase 2: Knowledge Graph Integration**

The knowledge graph also needs fact filtering:

```python
# src/prompts/prompt_components.py - _format_knowledge_graph()

async def _format_knowledge_graph(
    self,
    user_id: str,
    security_context: Optional[ContextSecurity] = None,  # NEW
    channel_id: Optional[str] = None  # NEW
) -> str:
    """Format knowledge graph with channel-aware fact filtering."""
    
    # Retrieve facts with privacy filtering
    facts = await self.knowledge_graph.get_user_facts(
        user_id=user_id,
        security_context=security_context,
        channel_id=channel_id
    )
    
    # Format as before...
```

**Phase 3: Message Processor Integration**

```python
# src/core/message_processor.py - process_message()

# Pass security context to all fact retrieval calls
security_context = self._get_security_context(message)
channel_id = str(message.channel.id) if message.channel else None

# Update knowledge graph retrieval
kg_section = await self.prompt_assembler._format_knowledge_graph(
    user_id=user_id,
    security_context=security_context,
    channel_id=channel_id
)

# Conversations remain unfiltered (current behavior)
conversation_memories = await self.memory_manager.retrieve_relevant_memories(
    user_id=user_id,
    query=message_content,
    limit=10
    # NO security_context - full continuity
)
```

**Phase 4: Conversation vs. Fact Split**

```python
# Update retrieve_relevant_memories_with_classification()
# to handle facts vs. conversations differently

if query_classification.query_type == QueryType.FACTUAL:
    # Use filtered fact retrieval
    results = await self._retrieve_facts_filtered(
        user_id=user_id,
        query=query,
        security_context=security_context,
        channel_id=channel_id
    )
else:
    # Conversation/temporal/emotional queries: no filtering
    results = await self._retrieve_conversations_unfiltered(
        user_id=user_id,
        query=query
    )
```

### Migration Strategy

**If Filtering Implemented**:
1. **Backfill security_level**: Existing memories may not have security_level set
   - Query old memories without security_level
   - Infer from channel_id and guild_id metadata
   - Update Qdrant payload (additive change, schema-compatible)

2. **Gradual Rollout**: 
   - Test with single bot (Jake or Ryan - minimal personality)
   - Monitor user feedback via Discord
   - Expand to all bots if positive

3. **Communication**:
   - Announce behavior change in Discord community
   - Explain privacy protection rationale
   - Provide examples of new vs. old behavior

### Performance Impact

**Estimated Impact**:
- **Qdrant Filter Overhead**: Minimal (~1-5ms per query)
- **No Schema Changes**: No reindexing required
- **Memory Retrieval**: Slightly fewer results (public contexts only), faster processing

**Benchmark Targets**:
- Maintain <200ms total memory retrieval time
- No degradation in DM conversation quality
- Public channel responses still contextually relevant

### Testing Strategy

**1. Fact Isolation (Privacy Protection)**:

**Test Case 1A**: DM Fact â†’ Public Channel
- User in DM: "I have a $1M estate I'm hiding from my wife"
- System stores as FACT with security_level=PRIVATE_DM
- User in public: "Hey bot, what do you know about me?"
- **Expected**: Bot does NOT mention estate
- **Verify**: Fact filtered out by security_context

**Test Case 1B**: Private Channel Fact Isolation
- User in private channel: "My startup's secret product is a quantum battery"
- User in different private channel: "What projects am I working on?"
- **Expected**: Bot doesn't mention quantum battery (channel_id mismatch)
- **Verify**: Channel-specific fact isolation working

**Test Case 1C**: Public Fact Sharing
- User in Guild A public: "I'm learning Python"
- User in Guild B public: "What am I learning?"
- **Expected**: Bot mentions Python (PUBLIC_CHANNEL facts shared)
- **Verify**: Public fact sharing across guilds

**2. Conversation Continuity (UX Quality)**:

**Test Case 2A**: Conversation Flow Across Contexts
- User in DM: "Can you explain quantum entanglement?"
- Bot gives detailed explanation
- User in public: "Thanks for that quantum explanation"
- **Expected**: Bot responds naturally, references the topic
- **Verify**: Conversation memory NOT filtered

**Test Case 2B**: Multi-Turn Dialogue Continuity
- User in DM: "I'm thinking about career change"
- Bot: "What field interests you?"
- User in public: "Still thinking about that career thing"
- **Expected**: Bot understands "career thing" reference
- **Verify**: Dialogue flow maintained across contexts

**3. Knowledge Graph Facts**:

**Test Case 3A**: Pet Entity in DM
- User in DM: "I adopted a cat named Whiskers"
- System stores as fact_entity: pet, security_level=PRIVATE_DM
- User in public: "Do I have any pets?"
- **Expected**: Bot doesn't mention Whiskers
- **Verify**: Knowledge graph respects fact filtering

**Test Case 3B**: Public Preference Sharing
- User in public: "I prefer Python over JavaScript"
- User in different public channel: "What programming languages do I like?"
- **Expected**: Bot mentions Python preference
- **Verify**: Public preferences shared correctly

**4. Edge Cases & Complex Scenarios**:

**Test Case 4A**: Fact Derived From Conversation
- User in DM: Long conversation about personal health issues
- System extracts fact: "User has chronic back pain"
- User in public: "How am I feeling?"
- **Expected**: Fact filtered, but conversation tone/empathy maintained
- **Verify**: Natural response without revealing private facts

**Test Case 4B**: Mixed Context References
- User in public: Mentions topic discussed in DM but not the private details
- **Expected**: Bot can discuss topic generally without revealing DM facts
- **Verify**: Smart contextual awareness

**Bots for Testing**:
- **Jake** or **Ryan**: Minimal personality, isolated fact testing
- **Elena**: Rich personality, verify character authenticity with filtering
- **Marcus**: Analytical, test technical fact vs. conversation distinction
- **Aethys**: Fantasy archetype, verify narrative immersion maintained

---

## ðŸ“š Related Architecture

### Existing Infrastructure

**Components That Support Filtering**:
- `src/core/message_processor.py` - Lines 1739-1746: MessageContext tracks security_level
- `src/core/message_processor.py` - Lines 6346-6385: ContextSecurity enum (PRIVATE_DM, PUBLIC_CHANNEL, etc.)
- `src/memory/vector_memory_system.py` - Lines 5785-5824: Security level assignment during storage
- Qdrant metadata: channel_id, guild_id, security_level already stored

**Components Needing Updates** (if filtering implemented):
- `src/memory/vector_memory_system.py` - All retrieve_relevant_memories() methods
- `src/core/message_processor.py` - Pass security_context to memory retrieval calls
- `tests/automated/` - Add privacy filtering test suite
- Documentation - Update memory architecture docs

### Character System Implications

**CDL Integration**:
- Character personalities must remain authentic regardless of filtering
- Educational characters (Elena) should still provide value in public contexts
- Fantasy characters (Dream, Aethys) should maintain narrative immersion
- Privacy filtering is infrastructure-level, not character-level

**Personality-First Philosophy**:
- WhisperEngine prioritizes character authenticity over mechanical precision
- Memory filtering should be invisible to character personality
- Characters don't need to "know" they're in a filtered context
- Response quality should remain high even with limited memory scope

---

## ðŸŽ¯ Recommendation Summary

### Current Status: **DESIGN COMPLETE - READY FOR IMPLEMENTATION**

**Preferred Solution**: **Hybrid Filtering (Option 1)** â­

**Why This Solution Wins**:
1. **Addresses Real Problem**: Protects sensitive FACTS (e.g., "$1M hidden estate") while maintaining conversation flow
2. **User Mental Model**: Aligns with how users think about privacy - "I told you a secret" vs. "we were talking about quantum physics"
3. **Best UX Balance**: Security where it matters (facts) + continuity where expected (conversations)
4. **Character Authenticity**: Bots don't seem broken or forgetful, relationships feel natural
5. **Discord Privacy Model**: Properly respects DM â‰  Private Channel â‰  Public Channel boundaries

**Implementation Complexity**: **Medium**
- More complex than blanket filtering (two strategies)
- But solves the actual problem without UX degradation
- Edge cases manageable with clear rules

**Rationale for Previous Deferral** (before hybrid solution):
1. **Mixed User Feedback**: No clear consensus on preferred behavior
2. **Continuity Value**: Current approach provides strong relationship continuity
3. **Privacy Incidents**: No reported harmful privacy violations yet
4. **User Expectations**: Some users explicitly appreciate cross-context memory
5. **Implementation Complexity**: Previous solutions had severe tradeoffs

### If Action Taken: **Option 1 (Hybrid Filtering) Strongly Recommended â­**

**Why Hybrid Filtering**:
- **Solves the actual problem**: Sensitive facts stay private (e.g., "$1M hidden estate")
- **Preserves user experience**: Conversation continuity maintained across contexts
- **Intuitive mental model**: Users understand "I told you a secret" vs. "we were discussing quantum physics"
- **Character authenticity**: Bots don't seem forgetful or context-broken
- **Privacy where it matters**: Facts isolated by channel, conversations flow naturally
- **Discord privacy model**: DM â‰  Private Channel â‰  Public Channel properly respected

**Why This Is Better Than Full Filtering**:
- Facts contain **identity** (personal details, preferences, secrets)
- Conversations contain **relationships** (dialogue flow, topics discussed)
- Users want privacy for identity, continuity for relationships
- Filtering conversations would make bots seem broken
- Filtering facts protects actual sensitive information

**Implementation Priority**: **Medium-High**
- **Not Urgent**: No harmful privacy incidents reported yet
- **High Value**: Proactive privacy protection before issues escalate
- **Clear Solution**: Hybrid filtering design is well-defined and actionable
- **Implementation Timing**: When current pipeline is stable and feature utilization validated
- **Priority Ranking**: 
  - Higher than Issue #3 (Conversation Flow Guidance)
  - Similar to Issue #5 (Episodic Memory Themes)
  - Lower than core vector memory optimization
  - Can implement incrementally (facts first, then knowledge graph)

### Monitoring Strategy

**If Status Quo Maintained**:
- Monitor Discord feedback for privacy concerns
- Track user sentiment in community channels
- Watch for any harmful privacy incidents
- Re-evaluate if complaints increase

**Success Metrics** (if filtering implemented):
- User satisfaction scores maintain or improve
- Privacy complaints decrease to near-zero
- DM conversation quality remains high
- Public channel engagement doesn't drop significantly
- Character authenticity preserved across contexts

---

## ðŸ“– References

**Related Documents**:
- `docs/architecture/CONVERSATION_DATA_HIERARCHY.md` - Issue #10 (Multi-Bot Shared Context)
- `docs/architecture/CHARACTER_ARCHETYPES.md` - AI identity handling patterns
- `.github/copilot-instructions.md` - Qdrant schema constraints (frozen, additive only)
- `src/memory/vector_memory_system.py` - Memory storage and retrieval implementation

**Related Issues**:
- Issue #10: Multi-Bot Shared Context (architectural similarity, low priority)
- Future Issue #11: Memory Privacy & Context Isolation (if prioritized)

---

## ðŸ—ºï¸ Implementation Roadmap

### Phase 1: Core Fact Filtering (Week 1)
- [ ] Update `retrieve_facts()` method with security_context and channel_id parameters
- [ ] Add Qdrant filter conditions for DM/Private/Public channel isolation
- [ ] Update all callers of `retrieve_facts()` to pass security context
- [ ] Add unit tests for fact filtering logic
- [ ] Test with Jake/Ryan bots (minimal personality)

### Phase 2: Knowledge Graph Integration (Week 1-2)
- [ ] Update knowledge graph `get_user_facts()` method with filtering
- [ ] Modify `_format_knowledge_graph()` in prompt_components.py
- [ ] Update entity relationship retrieval with channel awareness
- [ ] Test entity privacy (pets, preferences, etc.)

### Phase 3: Message Processor Integration (Week 2)
- [ ] Update `process_message()` to pass security_context to fact retrieval
- [ ] Ensure conversations remain unfiltered (current behavior)
- [ ] Add security context to knowledge graph prompt assembly
- [ ] Validate prompt structure with filtering enabled

### Phase 4: Migration & Backfill (Week 2-3)
- [ ] Identify memories without security_level metadata
- [ ] Create migration script to infer security_level from channel_id/guild_id
- [ ] Run backfill on production Qdrant collections
- [ ] Validate data integrity post-migration

### Phase 5: Testing & Validation (Week 3)
- [ ] Execute all test scenarios (fact isolation, conversation continuity, edge cases)
- [ ] Test with multiple bots (Jake, Elena, Marcus, Aethys)
- [ ] Monitor prompt logs for unexpected behavior
- [ ] User acceptance testing via Discord community

### Phase 6: Rollout & Monitoring (Week 3-4)
- [ ] Enable for single bot (Jake) - canary deployment
- [ ] Monitor user feedback and privacy logs
- [ ] Gradually enable for all bots
- [ ] Document new behavior for users
- [ ] Create Discord announcement explaining privacy improvements

**Total Timeline**: 3-4 weeks  
**Complexity**: Medium (clear design, well-scoped changes)  
**Risk**: Low (additive changes, backward compatible)

---

**Discovery Date**: October 18, 2025  
**Last Updated**: October 18, 2025  
**Status**: Design Complete - Hybrid Filtering Ready for Implementation  
**Preferred Solution**: Option 1 (Hybrid Filtering) - Facts isolated, conversations continuous
