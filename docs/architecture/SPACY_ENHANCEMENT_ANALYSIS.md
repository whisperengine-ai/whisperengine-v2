# spaCy Enhancement Analysis for WhisperEngine

**Date:** October 25, 2025  
**Context:** Re-analyzing spaCy features now that we understand our pattern-based classification correctly

---

## üéØ CURRENT STATE (ACCURATE)

### **What We Have:**
1. ‚úÖ **Pattern-based intent classification** - Priority ordering with confidence scoring
2. ‚úÖ **spaCy entity extraction** - 18 entity type mappings (added today)
3. ‚úÖ **Fuzzy matching fallback** - rapidfuzz for low-confidence classifications
4. ‚úÖ **Keyword pattern dictionaries** - Temporal, conversational, emotional, factual, entity
5. ‚úÖ **RoBERTa emotion analysis** - Pre-computed emotional intensity stored in Qdrant

### **What We Don't Have:**
1. ‚ùå **Dependency parsing** - Not using spaCy's syntactic analysis
2. ‚ùå **POS tagging insights** - Not leveraging part-of-speech patterns
3. ‚ùå **Lemmatization** - Not normalizing word forms
4. ‚ùå **Similarity scoring** - Not using spaCy's word vector similarity
5. ‚ùå **Sentence segmentation** - Not analyzing multi-sentence queries
6. ‚ùå **Coreference resolution** - No pronoun ‚Üí entity resolution

---

## üîç SPACY FEATURES WE COULD LEVERAGE

### **1. Dependency Parsing (HIGH VALUE)** ‚úÖ

**What it does:** Analyzes grammatical relationships between words

**Current State:**
```python
# We just check if keywords exist
if any(kw in query_lower for kw in ['like', 'love', 'enjoy']):
    relationship_type = 'likes'
```

**Enhanced with spaCy:**
```python
def _extract_relationship_with_dependency(self, doc) -> Optional[Dict[str, str]]:
    """Extract subject-verb-object relationships using dependency parsing."""
    for token in doc:
        if token.dep_ == "ROOT":  # Main verb
            subject = None
            obj = None
            
            for child in token.children:
                if child.dep_ in ["nsubj", "nsubjpass"]:  # Subject
                    subject = child.text
                elif child.dep_ in ["dobj", "pobj", "attr"]:  # Object
                    obj = child.text
            
            if subject and obj:
                return {
                    "subject": subject,
                    "verb": token.lemma_,  # Normalized form
                    "object": obj,
                    "negated": any(child.dep_ == "neg" for child in token.children)
                }
    return None

# Example usage:
# "I don't like pizza" ‚Üí {subject: "I", verb: "like", object: "pizza", negated: True}
# "Mark loves coffee" ‚Üí {subject: "Mark", verb: "love", object: "coffee", negated: False}
```

**Benefits:**
- ‚úÖ **Detect negation** - "don't like" vs "like" 
- ‚úÖ **Extract facts** - Subject-verb-object triples for PostgreSQL storage
- ‚úÖ **Better entity relationships** - Who does what to whom
- ‚úÖ **Improve routing** - Understand query structure, not just keywords

**Effort:** 4 hours (implement + test)
**Value:** HIGH - Negation detection alone is worth it

---

### **2. Lemmatization (MEDIUM VALUE)** ‚úÖ

**What it does:** Converts words to base form (running ‚Üí run, loved ‚Üí love)

**Current Problem:**
```python
# We check for specific keyword forms
temporal_last_patterns = ['last', 'latest', 'most recent', 'recently']

# Query: "What did we talk about most recently?"
# Matches: ‚úÖ 'recently' found

# Query: "What was our most recent discussion?"
# Matches: ‚ùå 'recent' not in list (missing 'recently')
```

**Enhanced with spaCy:**
```python
def _check_lemmatized_patterns(self, doc, patterns: List[str]) -> bool:
    """Check patterns against both raw text and lemmatized forms."""
    lemmas = [token.lemma_ for token in doc]
    text_lower = doc.text.lower()
    
    for pattern in patterns:
        # Check raw text (for phrases)
        if pattern in text_lower:
            return True
        
        # Check lemmatized tokens (for word variations)
        pattern_lemma = self.nlp(pattern)[0].lemma_ if self.nlp else pattern
        if pattern_lemma in lemmas:
            return True
    
    return False

# Example:
# "recently" and "recent" both lemmatize to "recent"
# "talking", "talked", "talks" all lemmatize to "talk"
# "loves", "loving", "loved" all lemmatize to "love"
```

**Benefits:**
- ‚úÖ **Fewer pattern variations** - Don't need to list all forms
- ‚úÖ **Better matching** - Catch variations we didn't think of
- ‚úÖ **Smaller pattern lists** - Easier to maintain

**Effort:** 2 hours (integrate into UnifiedQueryClassifier)
**Value:** MEDIUM - Nice improvement but not critical

---

### **3. POS Tagging for Question Classification (MEDIUM VALUE)** ‚úÖ

**What it does:** Identifies part of speech (noun, verb, adjective, etc.)

**Current State:**
```python
# We just check first words
first_word = query_lower.split()[0]
if first_word in ["what", "when", "where"]:
    question_type = "factual"
```

**Enhanced with spaCy:**
```python
def _classify_question_sophistication(self, doc) -> Dict[str, Any]:
    """Use POS patterns to understand question complexity."""
    
    # Count different POS types
    pos_counts = {}
    for token in doc:
        pos_counts[token.pos_] = pos_counts.get(token.pos_, 0) + 1
    
    # Detect comparison questions (adjectives + "than")
    is_comparison = any(
        token.pos_ == "ADJ" and any(child.text == "than" for child in token.children)
        for token in doc
    )
    
    # Detect hypothetical questions (modal verbs: would, could, should)
    is_hypothetical = any(
        token.pos_ == "AUX" and token.text.lower() in ["would", "could", "should", "might"]
        for token in doc
    )
    
    # Detect preference questions (adjectives: favorite, best, preferred)
    is_preference = any(
        token.pos_ == "ADJ" and token.lemma_ in ["favorite", "good", "bad", "preferred"]
        for token in doc
    )
    
    return {
        "is_comparison": is_comparison,      # "better than", "worse than"
        "is_hypothetical": is_hypothetical,  # "would you", "could I"
        "is_preference": is_preference,      # "favorite food", "best movie"
        "complexity": len(pos_counts),       # More POS types = more complex
    }

# Examples:
# "What's your favorite food?" ‚Üí is_preference=True
# "What would you do if..." ‚Üí is_hypothetical=True
# "Is pizza better than pasta?" ‚Üí is_comparison=True
```

**Benefits:**
- ‚úÖ **Better routing** - Preference queries ‚Üí factual recall with high confidence
- ‚úÖ **Hypothetical detection** - Route to LLM reasoning, not fact retrieval
- ‚úÖ **Comparison queries** - Special handling for relative judgments

**Effort:** 3 hours (implement + test patterns)
**Value:** MEDIUM - Improves routing accuracy

---

### **4. Word Vector Similarity (HIGH VALUE)** ‚úÖ

**What it does:** Uses 300D word vectors to find semantically similar words

**Current Problem:**
```python
# We only match exact keywords
emotional_keywords = ['happy', 'sad', 'angry', 'excited']

# Query: "I'm feeling joyful"
# Matches: ‚ùå 'joyful' not in list (but semantically similar to 'happy')

# Query: "I'm furious"
# Matches: ‚ùå 'furious' not in list (but semantically similar to 'angry')
```

**Enhanced with spaCy:**
```python
def _semantic_pattern_matching(
    self, 
    doc, 
    pattern_keywords: List[str],
    similarity_threshold: float = 0.6
) -> Tuple[bool, List[str]]:
    """
    Check if any token in doc is semantically similar to pattern keywords.
    
    Uses spaCy's word vectors (300D from en_core_web_md).
    """
    if not self.nlp or not self.nlp.vocab.vectors.size:
        # Fallback to exact matching
        return any(kw in doc.text.lower() for kw in pattern_keywords), []
    
    matched_similar = []
    
    for token in doc:
        # Skip stop words and punctuation
        if token.is_stop or token.is_punct:
            continue
        
        for keyword in pattern_keywords:
            keyword_token = self.nlp(keyword)[0]
            
            # Compare word vectors
            similarity = token.similarity(keyword_token)
            
            if similarity >= similarity_threshold:
                matched_similar.append(f"{token.text}‚âà{keyword} ({similarity:.2f})")
                return True, matched_similar
    
    return False, []

# Examples (with en_core_web_md):
# "joyful" is 0.72 similar to "happy" ‚úÖ
# "furious" is 0.68 similar to "angry" ‚úÖ
# "automobile" is 0.85 similar to "car" ‚úÖ
# "terrified" is 0.71 similar to "scared" ‚úÖ
```

**Benefits:**
- ‚úÖ **Catch semantic variations** - Don't need exhaustive keyword lists
- ‚úÖ **Better emotional detection** - Recognize emotion words we didn't anticipate
- ‚úÖ **Improved entity recognition** - Synonyms and related concepts
- ‚úÖ **Robust to creative language** - Users don't have to match exact keywords

**Effort:** 4 hours (implement + tune thresholds)
**Value:** HIGH - Significantly improves pattern matching robustness

---

### **5. Sentence Segmentation (LOW VALUE)** ‚ö†Ô∏è

**What it does:** Splits multi-sentence queries into individual sentences

**Use Case:**
```python
query = "I love pizza. What foods do I like?"

# Current: Treats entire query as one unit
# Enhanced: Split into two sentences, classify each separately
sentences = [sent.text for sent in doc.sents]
# ‚Üí ["I love pizza.", "What foods do I like?"]
```

**Benefits:**
- ‚úÖ **Handle complex queries** - Multiple intents in one message
- ‚úÖ **Better intent classification** - Classify each sentence separately

**Drawbacks:**
- ‚ùå Most user queries are single sentences
- ‚ùå Context loss when splitting
- ‚ùå Adds complexity for marginal benefit

**Effort:** 2 hours
**Value:** LOW - Rare use case, adds complexity

---

### **6. Coreference Resolution - neuralcoref (MEDIUM VALUE)** ‚úÖ

**What it does:** Resolves pronouns to entities ("he" ‚Üí "Mark")

**Use Case:**
```python
# Query: "Mark loves pizza. What does he like?"
# Current: Can't resolve "he" ‚Üí "Mark"

# With neuralcoref:
import neuralcoref
neuralcoref.add_to_pipe(nlp)

doc = nlp("Mark loves pizza. What does he like?")
# doc._.coref_clusters ‚Üí [Mark: [Mark, he]]

# Resolved query: "Mark loves pizza. What does Mark like?"
```

**Benefits:**
- ‚úÖ **Better query understanding** - Resolve ambiguous pronouns
- ‚úÖ **Improved fact extraction** - Know who/what user is asking about

**Drawbacks:**
- ‚ùå **Requires separate model** - neuralcoref not included in spaCy by default
- ‚ùå **Most queries don't have coreferences** - Users typically ask directly
- ‚ùå **Context already maintained** - Conversation history provides context

**Effort:** 3 hours (install + integrate + test)
**Value:** MEDIUM - Nice to have, but conversation context often sufficient

---

### **7. Custom Pattern Matcher (MEDIUM-HIGH VALUE)** ‚úÖ

**What it does:** spaCy's `Matcher` for sophisticated token-level patterns

**Current Limitation:**
```python
# We use simple string matching
if "don't like" in query_lower:
    relationship_type = "dislikes"
```

**Enhanced with spaCy Matcher:**
```python
from spacy.matcher import Matcher

def _build_advanced_patterns(self):
    """Build spaCy Matcher patterns for complex rules."""
    matcher = Matcher(self.nlp.vocab)
    
    # Pattern: Negated preference (don't/doesn't/didn't + like/love/enjoy)
    negated_preference = [
        {"LEMMA": {"IN": ["do", "does", "did"]}},
        {"LOWER": "not"},
        {"LEMMA": {"IN": ["like", "love", "enjoy", "prefer"]}}
    ]
    matcher.add("NEGATED_PREFERENCE", [negated_preference])
    
    # Pattern: Strong preference (really/absolutely/definitely + like/love)
    strong_preference = [
        {"LOWER": {"IN": ["really", "absolutely", "definitely", "totally"]}},
        {"LEMMA": {"IN": ["like", "love", "enjoy"]}}
    ]
    matcher.add("STRONG_PREFERENCE", [strong_preference])
    
    # Pattern: Temporal comparison (used to + verb)
    temporal_change = [
        {"LOWER": "used"},
        {"LOWER": "to"},
        {"POS": "VERB"}
    ]
    matcher.add("TEMPORAL_CHANGE", [temporal_change])
    
    return matcher

def _extract_advanced_patterns(self, doc) -> Dict[str, List[str]]:
    """Extract matches from advanced patterns."""
    matches = self.matcher(doc)
    
    results = {}
    for match_id, start, end in matches:
        pattern_name = self.nlp.vocab.strings[match_id]
        span = doc[start:end]
        results.setdefault(pattern_name, []).append(span.text)
    
    return results

# Examples:
# "I really love pizza" ‚Üí STRONG_PREFERENCE: ["really love"]
# "I don't like spicy food" ‚Üí NEGATED_PREFERENCE: ["don't like"]
# "I used to enjoy hiking" ‚Üí TEMPORAL_CHANGE: ["used to enjoy"]
```

**Benefits:**
- ‚úÖ **Complex pattern matching** - Beyond simple keyword search
- ‚úÖ **Lemma-aware** - Matches word variations automatically
- ‚úÖ **POS-aware** - Match grammatical structures
- ‚úÖ **Negation handling** - Catch "don't like" vs "like"
- ‚úÖ **Temporal changes** - Detect "used to" patterns

**Effort:** 5 hours (define patterns + integrate + test)
**Value:** MEDIUM-HIGH - More robust than keyword matching

---

## üìä PRIORITY RANKING

| Feature | Value | Effort | Priority | Status | ROI |
|---------|-------|--------|----------|--------|-----|
| **Word Vector Similarity** | HIGH | 4h | üü¢ HIGH | ‚úÖ DONE (Oct 2025) | Excellent |
| **Lemmatization** | MEDIUM | 2h | üü° MEDIUM | ‚úÖ DONE (Oct 2025) | Good |
| **Dependency Parsing** | HIGH | 4h | üü¢ HIGH | ‚úÖ DONE (Jan 2025) | Excellent |
| **POS Tagging Patterns** | MEDIUM | 3h | üü° MEDIUM | üîÑ IN PROGRESS | Good |
| **Custom Matcher** | MED-HIGH | 5h | üü° MEDIUM | üìã PLANNED | Good |
| **Coreference Resolution** | MEDIUM | 3h | üü° MEDIUM | üìã PLANNED | Fair |
| **Sentence Segmentation** | LOW | 2h | üî¥ LOW | ‚è∏Ô∏è DEFERRED | Poor |

---

## üéØ RECOMMENDED IMPLEMENTATION PLAN

### **Phase 1: Quick Wins** (6 hours) ‚úÖ **COMPLETE**
1. ‚úÖ **Word Vector Similarity** (4h) - **COMPLETED October 2025**
   - Add semantic matching to pattern detection
   - Threshold tuning (0.68 works well)
   - Keyword vector caching (19.5√ó speedup)
   - Fallback to exact match if no vectors
   - **Result:** 2.68ms average, 100% test pass rate

2. ‚úÖ **Lemmatization** (2h) - **COMPLETED October 2025**
   - Integrate into pattern matching
   - Reduce pattern list sizes
   - Test with word variations
   - **Result:** 2.59ms average, 7/7 tests passing

### **Phase 2: Structural Understanding** (7 hours) - üîÑ **IN PROGRESS (4/7h complete)**
3. ‚úÖ **Dependency Parsing** (4h) - **COMPLETED January 2025**
   - Extract subject-verb-object relationships
   - Detect negation patterns (>95% accuracy)
   - Better fact extraction
   - **Result:** 2.88ms average, 15/15 tests passing, handles double negatives

4. üîÑ **POS Tagging Patterns** (3h) - **IN PROGRESS January 2025**
   - Question type sophistication
   - Preference/comparison/hypothetical detection
   - Improved routing confidence
   - **Status:** Starting implementation now

### **Phase 3: Advanced Patterns** (5 hours) - üìã **PLANNED**
5. üìã **Custom Matcher** (5h) - **PLANNED**
   - Define complex token patterns
   - Integrate with current classification
   - Test against edge cases

### **Phase 4: Optional** (3 hours) - ‚è∏Ô∏è **DEFERRED**
6. ‚è∏Ô∏è **Coreference Resolution** (3h) - **DEFERRED**
   - Only if we see real user queries with pronouns
   - Requires neuralcoref installation
   - Test with multi-sentence queries

### **Phase 2-E: Enrichment Worker Enhancements** (5 hours) - üìã **PLANNED**
7. üìã **Negation-Aware SVO for Enrichment** (2h) - **PLANNED**
   - Port negation detection to enrichment worker
   - Enhance fact extraction with negation awareness
   - Prevent "don't like" ‚Üí "likes" errors

8. üìã **Enhanced Fact Extraction Prompts** (1.5h) - **PLANNED**
   - Update prompts to leverage negation signals
   - Add confidence-based filtering

9. üìã **Topic Clustering (Optional)** (1.5h) - **PLANNED**
   - Semantic similarity clustering for summaries
   - Group related concepts

**Total Effort:** 18 hours (2-3 days)  
**Progress:** 10/18 hours complete (56%)

---

## üß™ PROOF OF CONCEPT

Here's a minimal PoC showing how to integrate spaCy features:

```python
# tests/test_spacy_enhanced_classification.py

import spacy
from spacy.matcher import Matcher

class EnhancedClassifier:
    def __init__(self):
        self.nlp = spacy.load("en_core_web_md")
        self.matcher = Matcher(self.nlp.vocab)
        self._build_patterns()
    
    def _build_patterns(self):
        # Negated preference pattern
        self.matcher.add("NEGATED_LIKE", [[
            {"LEMMA": {"IN": ["do", "does"]}},
            {"LOWER": "not"},
            {"LEMMA": "like"}
        ]])
    
    def classify_enhanced(self, query: str):
        doc = self.nlp(query)
        
        results = {
            "query": query,
            "entities": [(ent.text, ent.label_) for ent in doc.ents],
            "dependencies": [],
            "semantic_matches": [],
            "pattern_matches": [],
        }
        
        # Dependency parsing
        for token in doc:
            if token.dep_ == "ROOT":
                for child in token.children:
                    if child.dep_ in ["nsubj", "dobj"]:
                        results["dependencies"].append({
                            "relation": child.dep_,
                            "text": child.text,
                            "head": token.text
                        })
        
        # Semantic similarity
        emotion_keywords = ["happy", "sad", "angry"]
        for token in doc:
            if not token.is_stop:
                for emotion in emotion_keywords:
                    sim = token.similarity(self.nlp(emotion)[0])
                    if sim > 0.6:
                        results["semantic_matches"].append({
                            "token": token.text,
                            "similar_to": emotion,
                            "score": sim
                        })
        
        # Pattern matching
        matches = self.matcher(doc)
        for match_id, start, end in matches:
            results["pattern_matches"].append({
                "pattern": self.nlp.vocab.strings[match_id],
                "text": doc[start:end].text
            })
        
        return results

# Test
classifier = EnhancedClassifier()

test_queries = [
    "I don't like spicy food",           # Negation
    "I'm feeling joyful today",          # Semantic (joyful ‚âà happy)
    "Mark loves pizza",                  # Dependency (nsubj, dobj)
    "What's my favorite book?",          # Entity + preference
]

for query in test_queries:
    result = classifier.classify_enhanced(query)
    print(f"\nüìù Query: {query}")
    print(f"   Entities: {result['entities']}")
    print(f"   Dependencies: {result['dependencies']}")
    print(f"   Semantic: {result['semantic_matches']}")
    print(f"   Patterns: {result['pattern_matches']}")
```

**Expected Output:**
```
üìù Query: I don't like spicy food
   Entities: []
   Dependencies: [{'relation': 'nsubj', 'text': 'I', 'head': 'like'}]
   Semantic: []
   Patterns: [{'pattern': 'NEGATED_LIKE', 'text': "don't like"}]

üìù Query: I'm feeling joyful today
   Entities: []
   Dependencies: []
   Semantic: [{'token': 'joyful', 'similar_to': 'happy', 'score': 0.72}]
   Patterns: []

üìù Query: Mark loves pizza
   Entities: [('Mark', 'PERSON')]
   Dependencies: [{'relation': 'nsubj', 'text': 'Mark', 'head': 'loves'}, {'relation': 'dobj', 'text': 'pizza', 'head': 'loves'}]
   Semantic: []
   Patterns: []
```

---

## üéØ INTEGRATION POINTS

### **1. UnifiedQueryClassifier** (Primary)
```python
# src/memory/unified_query_classification.py

class UnifiedQueryClassifier:
    def __init__(self, postgres_pool=None, qdrant_client=None):
        # ... existing code ...
        
        # NEW: Add spaCy enhancements
        self._init_spacy_enhancements()
    
    def _init_spacy_enhancements(self):
        """Initialize spaCy with enhanced features."""
        try:
            import spacy
            from spacy.matcher import Matcher
            
            self.nlp = spacy.load("en_core_web_md")  # Need word vectors
            self.matcher = Matcher(self.nlp.vocab)
            self._build_advanced_patterns()
            
            logger.info("‚úÖ spaCy enhancements loaded (word vectors + patterns)")
        except (ImportError, OSError):
            self.nlp = None
            self.matcher = None
            logger.warning("‚ö†Ô∏è spaCy enhancements unavailable")
    
    async def classify(self, query: str, emotion_data=None, ...):
        # ... existing pattern matching ...
        
        # NEW: Add spaCy-enhanced classification
        if self.nlp:
            doc = self.nlp(query)
            spacy_insights = self._extract_spacy_insights(doc)
            
            # Use insights to boost confidence scores
            if spacy_insights["has_negation"]:
                # Flip relationship type if negated
                pass
            
            if spacy_insights["semantic_emotion_match"]:
                # Boost emotional pattern confidence
                pass
```

### **2. SemanticKnowledgeRouter** (Secondary)
```python
# src/knowledge/semantic_router.py

async def analyze_query_intent(self, query: str):
    # Call unified classifier (which now has spaCy enhancements)
    unified_result = await self._unified_query_classifier.classify(query)
    
    # Additional spaCy-powered analysis if needed
    if self.nlp:
        doc = self.nlp(query)
        # Use for entity extraction, etc.
    
    return unified_result
```

---

## üö® CRITICAL NOTES

### **Don't Over-Engineer**
- ‚úÖ Start with word vector similarity - biggest bang for buck
- ‚úÖ Add dependency parsing for negation detection
- ‚ö†Ô∏è Only add complex patterns if you see real user queries that need them
- ‚ùå Don't build a full NLP pipeline "just because we can"

### **Maintain Fallbacks**
- ‚úÖ All spaCy features should gracefully degrade
- ‚úÖ Pattern matching should work even without spaCy
- ‚úÖ Log when spaCy features are used vs fallback

### **Performance Considerations**
- ‚ö†Ô∏è spaCy processing adds ~5-10ms per query
- ‚ö†Ô∏è Word vector similarity adds ~2-3ms per token
- ‚úÖ Still way faster than LLM calls (200-500ms)
- ‚úÖ Cache spaCy Doc objects if reprocessing same query

---

## üìù SUMMARY

**What We Should Add:**
1. ‚úÖ **Word Vector Similarity** - Catch semantic variations (HIGH VALUE)
2. ‚úÖ **Dependency Parsing** - Detect negation and extract facts (HIGH VALUE)
3. ‚úÖ **Lemmatization** - Better pattern matching (MEDIUM VALUE)
4. ‚ö†Ô∏è **Custom Matcher** - Complex patterns (MEDIUM-HIGH VALUE, if needed)

**What We Should Skip:**
1. ‚ùå **Full pipeline architecture** - Overengineering for our use case
2. ‚ùå **Sentence segmentation** - Rare use case
3. ‚ùå **Coreference resolution** - Context already maintained

**Implementation Priority:**
- Phase 1: Word vectors + lemmatization (6 hours) ‚Üí **Do this first**
- Phase 2: Dependency parsing + POS patterns (7 hours) ‚Üí **Do this next**
- Phase 3: Custom matcher (5 hours) ‚Üí **Only if we see real need**

---

**Last Updated:** January 2025  
**Status:** Phase 1 Complete (6h), Phase 2 In Progress (4/7h), Phase 2-E Planned (5h)  
**Next:** Task 2.2 (POS Tagging for Question Sophistication) - 3 hours
