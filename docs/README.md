# WhisperEngine v2 Documentation

> *"From countless conversations, a universe is born."*

Welcome to the WhisperEngine v2 documentation. This guide helps you navigate the various documents based on what you're trying to accomplish.

---

## ğŸš€ Quick Start

| I want to... | Read this |
|--------------|-----------|
| Understand the project vision | [WHISPERENGINE_2_DESIGN.md](./architecture/WHISPERENGINE_2_DESIGN.md) |
| See what's implemented vs planned | [IMPLEMENTATION_ROADMAP_OVERVIEW.md](./IMPLEMENTATION_ROADMAP_OVERVIEW.md) |
| Create a new character | [CREATING_NEW_CHARACTERS.md](./CREATING_NEW_CHARACTERS.md) |
| Deploy multiple bots | [MULTI_BOT_DEPLOYMENT.md](./MULTI_BOT_DEPLOYMENT.md) |
| Understand the philosophy | [MULTI_MODAL_PERCEPTION.md](./architecture/MULTI_MODAL_PERCEPTION.md) |

---

## ğŸ“ Documentation Structure

```
docs/
â”œâ”€â”€ README.md                          # You are here
â”œâ”€â”€ IMPLEMENTATION_ROADMAP_OVERVIEW.md # Master roadmap & status
â”œâ”€â”€ CREATING_NEW_CHARACTERS.md         # Character creation guide
â”œâ”€â”€ MULTI_BOT_DEPLOYMENT.md            # Running multiple bots
â”œâ”€â”€ PRIVACY_AND_DATA_SEGMENTATION.md   # Privacy model
â”œâ”€â”€ API_REFERENCE.md                   # REST API documentation
â”‚
â”œâ”€â”€ architecture/                      # How the system works
â”‚   â”œâ”€â”€ WHISPERENGINE_2_DESIGN.md      # Core design philosophy
â”‚   â”œâ”€â”€ MULTI_MODAL_PERCEPTION.md      # ğŸ§  The "senses" of AI characters
â”‚   â”œâ”€â”€ COGNITIVE_ENGINE.md            # Brain of the system
â”‚   â”œâ”€â”€ MEMORY_SYSTEM_V2.md            # Vector + graph memory
â”‚   â”œâ”€â”€ MESSAGE_FLOW.md                # Request lifecycle
â”‚   â”œâ”€â”€ DATA_MODELS.md                 # Database schemas
â”‚   â”œâ”€â”€ TRUST_EVOLUTION_SYSTEM.md      # Relationship progression
â”‚   â”œâ”€â”€ DISCORD_INTEGRATION.md         # Discord as sensory interface
â”‚   â”œâ”€â”€ VISION_PIPELINE.md             # Image processing
â”‚   â”œâ”€â”€ SUMMARIZATION_SYSTEM.md        # Memory consolidation
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ features/                          # Specific feature documentation
â”‚   â”œâ”€â”€ KNOWLEDGE_GRAPH_MEMORY.md      # Neo4j fact storage
â”‚   â”œâ”€â”€ TRUST_AND_EVOLUTION.md         # Trust system details
â”‚   â”œâ”€â”€ USER_PREFERENCES.md            # Learning user preferences
â”‚   â”œâ”€â”€ COMMON_GROUND.md               # Shared interest detection
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ testing/                           # Test suite documentation
â”‚   â”œâ”€â”€ REGRESSION_TESTING.md          # Automated API test suite
â”‚   â””â”€â”€ CHARACTERS.md                  # Character system & testing
â”‚
â”œâ”€â”€ roadmaps/                          # Future features & specs
â”‚   â”œâ”€â”€ EMERGENT_UNIVERSE.md           # ğŸŒŒ Universe modality
â”‚   â”œâ”€â”€ FEDERATED_MULTIVERSE.md        # ğŸŒ Multi-universe federation (DRAFT)
â”‚   â”œâ”€â”€ CHANNEL_LURKING.md             # Passive engagement
â”‚   â”œâ”€â”€ EMBEDDING_UPGRADE_768D.md      # Memory resolution upgrade
â”‚   â”œâ”€â”€ RESPONSE_PATTERN_LEARNING.md   # RLHF-style learning
â”‚   â””â”€â”€ completed/                     # Historical roadmaps
â”‚
â””â”€â”€ origin/                            # V1 historical documents
```

---

## ğŸ§  Core Philosophy: Multi-Modal Input Processing

WhisperEngine v2 is built on a key insight: **AI characters have no physical senses**. They can't see, hear, or feel. Instead, they process input through six modalities:

| Modality | Human Analog | Implementation |
|----------|--------------|----------------|
| ğŸŒŒ **Universe** | Proprioception + Social awareness | Neo4j graph (planets, travelers) |
| ğŸ‘ï¸ **Vision** | Sight | Multimodal LLM (GPT-4V, Claude) |
| ğŸ‘‚ **Audio** | Hearing | Whisper transcription |
| ğŸ’¬ **Text** | Language | LLM processing |
| ğŸ§  **Memory** | Episodic + Semantic | Qdrant + Neo4j |
| â¤ï¸ **Emotion** | Interoception | Trust scores, sentiment |

**Deep dive**: [MULTI_MODAL_PERCEPTION.md](./architecture/MULTI_MODAL_PERCEPTION.md)

---

## ğŸ—ï¸ Architecture Documents

### Core System
| Document | Description |
|----------|-------------|
| [WHISPERENGINE_2_DESIGN.md](./architecture/WHISPERENGINE_2_DESIGN.md) | Core design philosophy, why polyglot persistence |
| [COGNITIVE_ENGINE.md](./architecture/COGNITIVE_ENGINE.md) | The "brain" - how responses are generated |
| [MESSAGE_FLOW.md](./architecture/MESSAGE_FLOW.md) | Complete request lifecycle |
| [DATA_MODELS.md](./architecture/DATA_MODELS.md) | Four Pillars database schemas |

### Memory & Knowledge
| Document | Description |
|----------|-------------|
| [MEMORY_SYSTEM_V2.md](./architecture/MEMORY_SYSTEM_V2.md) | Hybrid vector + graph memory |
| [SUMMARIZATION_SYSTEM.md](./architecture/SUMMARIZATION_SYSTEM.md) | Memory consolidation |
| [KNOWLEDGE_GRAPH_MEMORY.md](./features/KNOWLEDGE_GRAPH_MEMORY.md) | Neo4j fact storage |

### Character & Evolution
| Document | Description |
|----------|-------------|
| [TRUST_EVOLUTION_SYSTEM.md](./architecture/TRUST_EVOLUTION_SYSTEM.md) | Relationship progression |
| [CREATING_NEW_CHARACTERS.md](./CREATING_NEW_CHARACTERS.md) | Character creation guide |

### Integration
| Document | Description |
|----------|-------------|
| [DISCORD_INTEGRATION.md](./architecture/DISCORD_INTEGRATION.md) | Discord as sensory interface |
| [VISION_PIPELINE.md](./architecture/VISION_PIPELINE.md) | Image processing (Sight modality) |

---

## ğŸ—ºï¸ Roadmap Documents

### Active Development
| Document | Status | Description |
|----------|--------|-------------|
| [IMPLEMENTATION_ROADMAP_OVERVIEW.md](./IMPLEMENTATION_ROADMAP_OVERVIEW.md) | ğŸ“‹ Master | Current status of all features |
| [EMBEDDING_UPGRADE_768D.md](./roadmaps/EMBEDDING_UPGRADE_768D.md) | ğŸ”´ Critical | Memory resolution upgrade |
| [CHANNEL_LURKING.md](./roadmaps/CHANNEL_LURKING.md) | ğŸŸ¡ Design | Passive engagement system |

### Future Vision
| Document | Status | Description |
|----------|--------|-------------|
| [EMERGENT_UNIVERSE.md](./roadmaps/EMERGENT_UNIVERSE.md) | ğŸŸ¡ Design | Universe modality - spatial/social awareness |
| [FEDERATED_MULTIVERSE.md](./roadmaps/FEDERATED_MULTIVERSE.md) | âš ï¸ Draft | Multi-universe federation protocol |
| [RESPONSE_PATTERN_LEARNING.md](./roadmaps/RESPONSE_PATTERN_LEARNING.md) | ğŸŸ¡ Design | RLHF-style learning |

### Completed Phases
Historical roadmaps in [`roadmaps/completed/`](./roadmaps/completed/) document what was built in each development phase.

---

## ğŸ”’ Privacy & Operations

| Document | Description |
|----------|-------------|
| [PRIVACY_AND_DATA_SEGMENTATION.md](./PRIVACY_AND_DATA_SEGMENTATION.md) | How user data is isolated |
| [MULTI_BOT_DEPLOYMENT.md](./MULTI_BOT_DEPLOYMENT.md) | Running multiple characters |
| [INFRASTRUCTURE_DEPLOYMENT.md](./architecture/INFRASTRUCTURE_DEPLOYMENT.md) | Docker, databases, scaling |

---

## ğŸ§ª Testing

| Document | Description |
|----------|-------------|
| [REGRESSION_TESTING.md](./testing/REGRESSION_TESTING.md) | Automated API test suite, all options |
| [CHARACTERS.md](./testing/CHARACTERS.md) | Character system overview & testing |

### Quick Test Commands

```bash
# Smoke test (fastest - health + greeting)
python tests_v2/run_regression.py --smoke

# Test specific bot
python tests_v2/run_regression.py --bot elena

# Test specific category
python tests_v2/run_regression.py --category memory

# Full regression suite
python tests_v2/run_regression.py

# Generate HTML report
python tests_v2/run_regression.py --report
```

---

## ğŸŒŒ The Grand Vision

WhisperEngine v2 isn't just a chatbot platform. It's building toward a **federated multiverse** where:

1. **Characters are persistent entities** with consistent behavior across six input modalities
2. **Each deployment is a universe** with its own characters, planets (Discord servers), and inhabitants (users)
3. **Universes can federate** to form a multiverse where characters travel and users explore
4. **No central authority** - peer-to-peer, like email or Mastodon

**Vision documents**:
- [MULTI_MODAL_PERCEPTION.md](./architecture/MULTI_MODAL_PERCEPTION.md) - How characters perceive
- [EMERGENT_UNIVERSE.md](./roadmaps/EMERGENT_UNIVERSE.md) - Spatial/social awareness
- [FEDERATED_MULTIVERSE.md](./roadmaps/FEDERATED_MULTIVERSE.md) - Multi-universe protocol (Draft)

---

## ğŸ“š Reading Order for New Contributors

1. **Start here**: [WHISPERENGINE_2_DESIGN.md](./architecture/WHISPERENGINE_2_DESIGN.md) - Understand the "why"
2. **Philosophy**: [MULTI_MODAL_PERCEPTION.md](./architecture/MULTI_MODAL_PERCEPTION.md) - How characters process multi-modal input
3. **Status**: [IMPLEMENTATION_ROADMAP_OVERVIEW.md](./IMPLEMENTATION_ROADMAP_OVERVIEW.md) - What's built vs planned
4. **Deep dive**: Pick architecture docs based on what you're working on

---

## ğŸ”§ For Developers

The codebase follows patterns documented in the architecture docs:

- **Manager Pattern**: Every subsystem has an `XManager` class with `initialize()` method
- **Async/Await**: All I/O is async with type hints
- **Feature Flags**: Expensive operations gated by settings
- **Parallel Retrieval**: Use `asyncio.gather` for multi-DB context fetching

**Key code locations**:
```
src_v2/
â”œâ”€â”€ agents/          # Cognitive engine, LLM interactions
â”œâ”€â”€ memory/          # Qdrant vectors, summarization
â”œâ”€â”€ knowledge/       # Neo4j graph
â”œâ”€â”€ evolution/       # Trust, feedback
â”œâ”€â”€ discord/         # Bot, commands, scheduler
â”œâ”€â”€ voice/           # TTS, audio processing
â””â”€â”€ api/             # FastAPI endpoints
```

---

## ğŸ“ Document Conventions

- **ğŸŸ¢ Implemented**: Feature is complete and in production
- **ğŸŸ¡ Design**: Specification complete, not yet implemented
- **âš ï¸ Draft**: Vision document, subject to change
- **ğŸ”´ Critical**: High priority, do soon

Cross-references use relative paths: `[Doc](./path/to/doc.md)`

---

*Last updated: November 25, 2025*
