#!/usr/bin/env python3
"""
Test Docker Build Model Pre-download
===================================

Validates that the updated Docker build scripts will correctly pre-download
the new sentence-transformers/all-MiniLM-L6-v2 embedding model.
"""

import os
import sys
import tempfile
from pathlib import Path

def test_docker_model_download():
    """Test the Docker model download configuration"""
    
    print("ğŸ³ Docker Build Model Pre-download Test")
    print("=" * 45)
    
    # Test 1: Verify download script uses correct model
    print("1. ğŸ“‹ Checking download script configuration...")
    
    script_path = Path("scripts/download_models.py")
    if script_path.exists():
        with open(script_path, 'r') as f:
            script_content = f.read()
        
        if 'sentence-transformers/all-MiniLM-L6-v2' in script_content:
            print("   âœ… Download script uses sentence-transformers/all-MiniLM-L6-v2")
        else:
            print("   âŒ Download script not updated with new model")
            return False
            
        if 'BAAI/bge-small-en-v1.5' in script_content and 'upgrade_from' in script_content:
            print("   âœ… Legacy model reference updated appropriately")
        else:
            print("   âš ï¸  Legacy model references may need cleanup")
    else:
        print("   âŒ Download script not found")
        return False
    
    # Test 2: Verify Dockerfile.bundled-models configuration
    print("\n2. ğŸ³ Checking Dockerfile configuration...")
    
    dockerfile_path = Path("Dockerfile.bundled-models")
    if dockerfile_path.exists():
        with open(dockerfile_path, 'r') as f:
            dockerfile_content = f.read()
        
        if 'scripts/download_models.py' in dockerfile_content:
            print("   âœ… Dockerfile copies and runs download script")
        else:
            print("   âŒ Dockerfile doesn't run download script")
            return False
            
        if 'FASTEMBED_CACHE_PATH' in dockerfile_content:
            print("   âœ… Dockerfile sets FastEmbed cache path")
        else:
            print("   âš ï¸  FastEmbed cache path may not be set")
    else:
        print("   âš ï¸  Dockerfile.bundled-models not found")
    
    # Test 3: Verify production configuration
    print("\n3. ğŸ­ Checking production configuration...")
    
    prod_compose_path = Path("docker-compose.prod.yml")
    if prod_compose_path.exists():
        with open(prod_compose_path, 'r') as f:
            prod_content = f.read()
        
        if 'sentence-transformers/all-MiniLM-L6-v2' in prod_content:
            print("   âœ… Production config uses new model")
        else:
            print("   âš ï¸  Production config may not be updated")
    
    # Test 4: Environment configuration consistency
    print("\n4. âš™ï¸  Checking environment consistency...")
    
    env_files = ['.env', '.env.template'] + [f'.env.{bot}' for bot in 
                ['elena', 'marcus', 'jake', 'dream', 'aethys', 'ryan', 'gabriel', 'sophia']]
    
    consistent_configs = 0
    for env_file in env_files:
        env_path = Path(env_file)
        if env_path.exists():
            with open(env_path, 'r') as f:
                env_content = f.read()
            
            if 'EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2' in env_content:
                consistent_configs += 1
    
    print(f"   ğŸ“Š Environment files with new model: {consistent_configs}/{len([p for p in env_files if Path(p).exists()])}")
    
    if consistent_configs > 5:  # Most configs updated
        print("   âœ… Environment configurations mostly consistent")
    else:
        print("   âš ï¸  Environment configurations may need more updates")
    
    # Test 5: Model cache verification
    print("\n5. ğŸ’¾ Testing model availability...")
    
    try:
        from fastembed import TextEmbedding
        
        # Test that the new model can be loaded
        model = TextEmbedding(model_name='sentence-transformers/all-MiniLM-L6-v2')
        test_embedding = list(model.embed(['cache test']))[0]
        
        print(f"   âœ… Model loads successfully: {len(test_embedding)}D")
        
        # Check cache location
        cache_dir = os.path.expanduser('~/.cache/fastembed')
        if os.path.exists(cache_dir):
            print(f"   âœ… Cache directory exists: {cache_dir}")
        else:
            print(f"   âš ï¸  Cache directory not found: {cache_dir}")
            
    except Exception as e:
        print(f"   âŒ Model loading failed: {e}")
        return False
    
    # Summary
    print("\nğŸ¯ DOCKER BUILD READINESS:")
    print("=" * 30)
    print("âœ… Download script updated with new model")
    print("âœ… Dockerfile configured for model pre-download")
    print("âœ… Environment configurations updated")
    print("âœ… Model tested and working locally")
    print()
    print("ğŸš€ NEXT BUILD STEPS:")
    print("1. docker build -f Dockerfile.bundled-models -t whisperengine:latest .")
    print("2. Model will be pre-downloaded during build stage")
    print("3. Runtime containers will use cached model (no downloads)")
    print()
    print("ğŸ“ MODEL CACHE LOCATIONS IN CONTAINER:")
    print("   â€¢ FastEmbed cache: /root/.cache/fastembed")
    print("   â€¢ Development cache: /app/.cache/fastembed")
    print("   â€¢ Model config: /app/models/model_config.json")
    
    return True

if __name__ == "__main__":
    success = test_docker_model_download()
    if success:
        print("\nğŸ‰ Docker build configuration ready for new embedding model!")
    else:
        print("\nâš ï¸  Some configuration issues detected. Review and fix before building.")
    
    sys.exit(0 if success else 1)