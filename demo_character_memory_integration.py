"""
Character Memory Integration Demo

This script demonstrates how to integrate the character memory system 
with WhisperEngine's main conversation flows and existing memory system.
"""

import os
import sys
import asyncio
import logging
from pathlib import Path

# Add src to path for imports  
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import logging
from src.characters import (
    get_character_bridge, 
    create_conversation_enhancer,
    Character
)# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def demo_character_memory_integration():
    """Demonstrate character memory integration with conversation flow"""
    
    print("ğŸ­ WhisperEngine Character Memory Integration Demo")
    print("=" * 60)
    
    # Step 1: Create a test character programmatically
    print("\nğŸ“ Step 1: Creating test character...")
    
    character = Character()
    character.metadata.character_id = "demo_elena_rodriguez"
    character.identity.name = "Elena Rodriguez"
    character.identity.age = 32
    character.identity.occupation = "Clinical Psychologist"
    character.identity.location = "Barcelona, Spain"
    
    # Add some background
    character.backstory.family_background = "Raised in a multicultural family with deep empathy for diverse perspectives"
    character.backstory.major_life_events = [
        "Moved to Barcelona at age 10",
        "Studied psychology at university", 
        "Started private therapy practice",
        "Specialized in trauma and emotional intelligence"
    ]
    
    print(f"âœ… Created character: {character.identity.name}")
    
    # Step 2: Get the character bridge and initialize
    print("\nğŸŒ‰ Step 2: Initializing character bridge...")
    
    bridge = get_character_bridge()
    
    # Since we have a programmatic character, we'll add it directly
    bridge._loaded_characters[character.metadata.character_id] = character
    
    from src.characters.memory.integration import CharacterMemoryIntegrator, CharacterMemoryContextProvider
    integrator = CharacterMemoryIntegrator(character)
    bridge._active_integrators[character.metadata.character_id] = integrator
    
    context_provider = CharacterMemoryContextProvider(integrator)
    bridge._context_providers[character.metadata.character_id] = context_provider
    
    print(f"âœ… Bridge initialized with character: {character.identity.name}")
    
    # Step 3: Create conversation enhancer
    print("\nğŸ’¬ Step 3: Setting up conversation enhancer...")
    
    enhancer = create_conversation_enhancer()
    enhancer.active_character_id = character.metadata.character_id
    
    print("âœ… Conversation enhancer ready")
    
    # Step 4: Simulate conversation workflow
    print("\nğŸ¤– Step 4: Simulating conversation workflow...")
    
    # Base system prompt (like WhisperEngine would use)
    base_system_prompt = """
You are an AI assistant trained to be helpful, harmless, and honest.
You should respond thoughtfully to user questions and provide helpful information.
"""
    
    # User message
    user_message = "I've been struggling with anxiety lately and feel overwhelmed by daily life"
    
    print(f"User: {user_message}")
    
    # Step 5: Enhance system prompt with character memories
    print("\nğŸ§  Step 5: Enhancing prompt with character memories...")
    
    enhanced_prompt, character_context = await enhancer.enhance_response_generation(
        user_message, base_system_prompt
    )
    
    print("âœ… System prompt enhanced with character memories")
    print(f"Memory count: {character_context.get('memory_context', {}).get('memory_count', 0)}")
    print(f"Development level: {character_context.get('memory_context', {}).get('character_development_level', 'none')}")
    
    # Show enhanced prompt (truncated)
    if len(enhanced_prompt) > len(base_system_prompt):
        print("ğŸ“ Enhanced prompt includes character memory context!")
        memory_section = enhanced_prompt[len(base_system_prompt):].strip()
        print(f"Memory addition preview: {memory_section[:200]}...")
    
    # Step 6: Simulate character response
    print("\nğŸ’­ Step 6: Simulating character response...")
    
    # This would normally be generated by LLM with enhanced prompt
    character_response = """I understand that anxiety can feel overwhelming, especially when it affects your daily routine. 
As someone who has worked with many clients experiencing similar challenges, I want you to know that what you're 
feeling is valid and manageable. From my experience, breaking down daily tasks into smaller, achievable steps 
can help reduce that sense of overwhelm. Would you like to explore some specific coping strategies together?"""
    
    print(f"Elena: {character_response}")
    
    # Step 7: Process conversation for character memory
    print("\nğŸ“š Step 7: Processing conversation for character memory...")
    
    # Simulate emotional context (like from emotional AI)
    emotional_context = {
        'emotions': {'empathy': 0.8, 'concern': 0.6, 'professional_warmth': 0.7},
        'intensity': 0.6
    }
    
    memory_created = await enhancer.process_conversation_interaction(
        user_message, character_response, emotional_context
    )
    
    print(f"âœ… Character memory created: {memory_created}")
    
    # Step 8: Check character development
    print("\nğŸ“Š Step 8: Character development status...")
    
    character_info = enhancer.get_character_info()
    memory_stats = bridge.get_character_memory_statistics(character.metadata.character_id)
    
    print(f"Character: {character_info['name']}")
    print(f"Total memories: {memory_stats.get('total_memories', 0)}")
    print(f"Average emotional weight: {memory_stats.get('average_emotional_weight', 0.0):.2f}")
    print(f"Development level: {character_info['development_level']}")
    
    # Step 9: Demonstrate memory recall for next conversation
    print("\nğŸ”„ Step 9: Demonstrating memory recall for future conversations...")
    
    # Simulate another user message
    next_user_message = "How do you think past experiences shape our ability to handle stress?"
    
    print(f"User: {next_user_message}")
    
    # Get character context for this new message
    next_context = await bridge.get_character_context_for_conversation(
        character.metadata.character_id,
        conversation_themes=['stress', 'experiences', 'psychology'],
        user_message=next_user_message
    )
    
    print("âœ… Character context retrieved for new conversation")
    print(f"Relevant memories: {next_context['memory_context']['memory_count']}")
    print(f"Response hints available: {len(next_context['response_hints'])}")
    
    # Step 10: Show integration with existing memory system
    print("\nğŸ”— Step 10: Integration with existing memory system...")
    
    # This demonstrates how character memories can work alongside user conversation memories
    print("Character memories are separate from user conversation memories")
    print("But both can be used together to create rich, consistent AI interactions")
    print(f"Character {character.identity.name} maintains personal continuity across conversations")
    
    # Step 11: Daily reflection
    print("\nğŸŒ… Step 11: Adding daily reflection...")
    
    reflection_added = await bridge.add_character_daily_reflection(
        character.metadata.character_id, 
        themes=['therapy_session', 'helping_others', 'empathy']
    )
    
    print(f"âœ… Daily reflection added: {reflection_added}")
    
    # Final status
    final_stats = bridge.get_character_memory_statistics(character.metadata.character_id)
    print("Final character memory status:")
    print(f"Total memories: {final_stats.get('total_memories', 0)}")
    print(f"Memory types: {final_stats.get('memories_by_type', {})}")
    
    print("\n" + "=" * 60)
    print("âœ… Character Memory Integration Demo Complete!")
    print("ğŸ¯ The character system is ready for integration with WhisperEngine")


async def demo_integration_points():
    """Demonstrate specific integration points with WhisperEngine components"""
    
    print("\nğŸ”§ Integration Points with WhisperEngine Components:")
    print("-" * 50)
    
    print("1. ğŸ“ Prompt Engineering Integration:")
    print("   - enhance_system_prompt_with_character_memories()")
    print("   - Injects character memories into system prompts")
    print("   - Maintains character consistency across conversations")
    
    print("\n2. ğŸ’¬ Conversation Handler Integration:")
    print("   - ConversationCharacterEnhancer class")
    print("   - Wraps conversation flows with character memory")
    print("   - Works with existing discord/desktop handlers")
    
    print("\n3. ğŸ§  Memory System Integration:")
    print("   - Character memories separate from user memories")
    print("   - Compatible with existing ContextAwareMemoryManager")
    print("   - Can be used alongside ChromaDB and Redis systems")
    
    print("\n4. ğŸ­ Universal Platform Integration:")
    print("   - Works with both Discord bot and desktop app")
    print("   - Character context available in universal_chat.py")
    print("   - Bridge pattern allows clean integration")
    
    print("\n5. ğŸ“Š Database Integration:")
    print("   - SQLite for desktop app (local privacy)")
    print("   - PostgreSQL for production (scalable)")
    print("   - Automatic database switching via environment")
    
    print("\n6. ğŸ”„ Phase 2-4 AI Integration:")
    print("   - Character memories enhance emotional intelligence")
    print("   - Provides context for phase 3 memory networks")
    print("   - Supports phase 4 human-like conversation adaptation")


def show_implementation_example():
    """Show concrete implementation examples"""
    
    print("\nğŸ’» Implementation Examples:")
    print("-" * 30)
    
    print("""
# In conversation handler (e.g., src/handlers/conversation.py)
from src.characters import create_conversation_enhancer

class ConversationHandler:
    def __init__(self):
        self.character_enhancer = create_conversation_enhancer()
        
    async def setup_character(self, character_file_path):
        await self.character_enhancer.set_active_character(character_file_path)
    
    async def generate_response(self, user_message, system_prompt):
        # Enhance with character memories
        enhanced_prompt, context = await self.character_enhancer.enhance_response_generation(
            user_message, system_prompt
        )
        
        # Use enhanced prompt with LLM
        response = await self.llm_client.generate_response(enhanced_prompt, user_message)
        
        # Process interaction for character memory
        await self.character_enhancer.process_conversation_interaction(
            user_message, response
        )
        
        return response
""")
    
    print("""
# In universal_chat.py integration
from src.characters import get_character_bridge

class UniversalChatPlatform:
    def __init__(self):
        self.character_bridge = get_character_bridge()
        
    async def process_message(self, user_id, message, character_id=None):
        if character_id:
            # Get character context
            context = await self.character_bridge.get_character_context_for_conversation(
                character_id, themes=self.extract_themes(message), user_message=message
            )
            
            # Use context in response generation...
""")


if __name__ == "__main__":
    # Run the complete demo
    asyncio.run(demo_character_memory_integration())
    
    # Show integration points
    asyncio.run(demo_integration_points())
    
    # Show implementation examples
    show_implementation_example()
    
    print("\nğŸ‰ Character Memory System Demo Complete!")
    print("Ready for integration with WhisperEngine main system!")