# =======================================================
# WhisperEngine Quick Start Configuration
# Copy to .env and set your Discord bot token to get started
# =======================================================

# üöÄ QUICK START STEPS:
#   1. Copy this file to .env
#   2. Set DISCORD_BOT_TOKEN (get from https://discord.com/developers/applications)
#   3. Choose your LLM provider below
#   4. Run: ./bot.sh start dev

# =======================================================
# DISCORD CONFIGURATION (REQUIRED)
# =======================================================
DISCORD_BOT_TOKEN=your_discord_bot_token_here
DISCORD_BOT_NAME=WhisperEngine
ADMIN_USER_IDS=your_discord_user_id_here

# =======================================================
# CHARACTER CONFIGURATION
# =======================================================
# Choose your AI's personality (CDL Character Definition Language)
CDL_DEFAULT_CHARACTER=characters/default_assistant.json

# Other character options:
# CDL_DEFAULT_CHARACTER=characters/dream_of_the_endless.json           # ‚ú® Dream from The Sandman
# CDL_DEFAULT_CHARACTER=characters/examples/elena-rodriguez.json       # üåä Marine biologist & researcher
# CDL_DEFAULT_CHARACTER=characters/examples/marcus-chen.json           # üéÆ Indie game developer

# Character System Features (Quick Start - Basic Setup)
ENABLE_MULTI_ENTITY_RELATIONSHIPS=true
ENABLE_CHARACTER_CREATION=true
ENABLE_ROLEPLAY_COMMANDS=true
MAX_CHARACTERS_PER_USER=5

# =======================================================
# LLM PROVIDER (CHOOSE ONE)
# =======================================================

# üè† OPTION 1: LOCAL LM STUDIO (Free, Private, Recommended)
# 1. Download from: https://lmstudio.ai
# 2. Download a model (e.g., Llama 3.2 3B)
# 3. Start local server (default port 1234)
# 4. Uncomment these lines:
# LLM_CHAT_API_URL=http://localhost:1234/v1
# LLM_CHAT_API_KEY=not-needed
# LLM_CHAT_MODEL=local-model

# üåê OPTION 2: OPENROUTER (Easy, Multiple Models) - ACTIVE
LLM_CHAT_API_URL=https://openrouter.ai/api/v1
LLM_CHAT_API_KEY=your_openrouter_api_key_here
LLM_CHAT_MODEL=openai/gpt-4o-mini

# ü§ñ OPTION 3: OPENAI DIRECT (Premium)
# 1. Get API key from: https://platform.openai.com/api-keys
# 2. Uncomment and set your key:
# LLM_CHAT_API_URL=https://api.openai.com/v1
# LLM_CHAT_API_KEY=your_openai_api_key_here
# LLM_CHAT_MODEL=gpt-4o-mini

# =======================================================
# MEMORY SYSTEM (VECTOR-NATIVE - VALIDATED DEFAULTS)
# =======================================================
MEMORY_SYSTEM_TYPE=vector
VECTOR_QDRANT_HOST=qdrant
VECTOR_QDRANT_PORT=6333
VECTOR_QDRANT_COLLECTION=whisperengine_memory
VECTOR_EMBEDDING_MODEL=snowflake/snowflake-arctic-embed-xs

# Enhanced Memory Features (Phase 1 & 2 - Basic Settings)
ENABLE_PHASE1_ENHANCED_MEMORY=true
ENABLE_PHASE2_THREE_TIER_MEMORY=true
PHASE2_MEMORY_DECAY_ENABLED=true
PHASE2_MEMORY_DECAY_RATE=0.1
DISABLE_PHASE2_EMOTION=false

# Database connections (for Docker environment)
POSTGRESQL_HOST=postgres
POSTGRESQL_PORT=5432
POSTGRESQL_DATABASE=whisper_engine
POSTGRESQL_USERNAME=bot_user
POSTGRESQL_PASSWORD=securepassword123

REDIS_HOST=redis
REDIS_PORT=6379

# =======================================================
# BASIC SETTINGS
# =======================================================
LOG_LEVEL=INFO
CONSOLE_LOG_LEVEL=INFO
DEBUG_MODE=false
HEALTH_CHECK_PORT=9090

# =======================================================
# ADVANCED AI FEATURES (QUICK START - ENABLED)
# =======================================================
# Core AI features enabled for quick start experience
ENABLE_PHASE3_MEMORY_NETWORKS=true
ENABLE_PHASE4_INTELLIGENCE=true
EXPERIMENTAL_FEATURES_ENABLED=true
BETA_MEMORY_FEATURES=true
BETA_CONVERSATION_FEATURES=true

# =======================================================
# üéâ YOU'RE READY!
# Run: ./bot.sh start dev
# 
# Need more features? Check other example files:
# ‚Ä¢ config/examples/.env.development.example - Full development features  
# ‚Ä¢ config/examples/.env.production.example - Production deployment
# ‚Ä¢ config/examples/.env.local-ai.example - Local AI focus
# ‚Ä¢ config/examples/.env.enterprise.example - All enterprise features
# =======================================================